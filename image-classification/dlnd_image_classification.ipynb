{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t\t\t\t  image_classification.meta\r\n",
      "__pycache__\t\t\t\t  preprocess_batch_1.p\r\n",
      "checkpoint\t\t\t\t  preprocess_batch_2.p\r\n",
      "command.sh\t\t\t\t  preprocess_batch_3.p\r\n",
      "dlnd_image_classification.ipynb\t\t  preprocess_batch_4.p\r\n",
      "floyd_requirements.txt\t\t\t  preprocess_batch_5.p\r\n",
      "helper.py\t\t\t\t  preprocess_test.p\r\n",
      "image_classification.data-00000-of-00001  preprocess_validation.p\r\n",
      "image_classification.index\t\t  problem_unittests.py\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf cifar-10-batches-py\n",
    "!rm cifar-10-python.tar.gz\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [00:30, 5.58MB/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ccc60a358>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.array(x / 255)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function \n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, \n",
    "                          shape = [None, image_shape[0], image_shape[1], image_shape[2]],\n",
    "                          name = \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, \n",
    "                          shape = [None, n_classes],\n",
    "                          name = \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # Create the weight and bias using conv_ksize, conv_num_outputs and the shape of x_tensor\n",
    "    channels = x_tensor.get_shape().as_list()[3]\n",
    "    \n",
    "    weights = tf.Variable(tf.random_normal([conv_ksize[0], \n",
    "                                            conv_ksize[1], \n",
    "                                            channels, \n",
    "                                            conv_num_outputs], \n",
    "                                            stddev=0.1))\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    # Apply a convolution to x_tensor using weight and conv_strides\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, \n",
    "                                     weights, \n",
    "                                     strides = [1, conv_strides[0], conv_strides[1], 1],\n",
    "                                     padding = \"SAME\")\n",
    "    \n",
    "    # Add bias\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    \n",
    "    # Add a nonlinear activation to the convolution\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    # Apply Max Pooling using pool_ksize and pool_strides\n",
    "    conv_layer = tf.nn.max_pool(conv_layer,\n",
    "                               ksize = [1, pool_ksize[0], pool_ksize[1], 1],\n",
    "                               strides = [1, pool_strides[0], pool_strides[1], 1],\n",
    "                               padding = \"SAME\")\n",
    "    return conv_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dims = x_tensor.get_shape().as_list()\n",
    "    batch_size = dims[0]\n",
    "    height = dims[1]\n",
    "    width = dims[2]\n",
    "    depth = dims[3]\n",
    "    \n",
    "    flattened = int(height * width * depth)\n",
    "    \n",
    "    return tf.reshape(x_tensor, [-1, flattened])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.random_normal([x_tensor.get_shape().as_list()[1], num_outputs], stddev=0.1)) \n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    fully_conn = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    fully_conn = tf.nn.relu(fully_conn)\n",
    "    return fully_conn\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.random_normal([x_tensor.get_shape().as_list()[1], num_outputs], stddev=0.1)) \n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    fully_conn = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    return fully_conn\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_ksize = (8, 8)\n",
    "    conv_strides = (4, 4)\n",
    "    pool_ksize = (4, 4)\n",
    "    pool_strides = (2, 2)\n",
    "    conv_num_outputs_1 = 32\n",
    "    conv_num_outputs_2 = 64\n",
    "    conv_num_outputs_3 = 128\n",
    "    \n",
    "\n",
    "    conv_layer_1 = conv2d_maxpool(x, conv_num_outputs_1, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_layer_2 = conv2d_maxpool(conv_layer_1, conv_num_outputs_2, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_layer_3 = conv2d_maxpool(conv_layer_2, conv_num_outputs_3, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    conv_layer_4 = flatten(conv_layer_3)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fully_conn_layer_1 = fully_conn(conv_layer_4, 20)\n",
    "    fully_conn_layer_1_dropout = tf.nn.dropout(fully_conn_layer_1, keep_prob = keep_prob)\n",
    "    \n",
    "    fully_conn_layer_2 = fully_conn(fully_conn_layer_1_dropout, 20)\n",
    "    fully_conn_layer_2_dropout = tf.nn.dropout(fully_conn_layer_2, keep_prob = keep_prob)\n",
    "\n",
    "\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    return output(fully_conn_layer_2_dropout, 10)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, \n",
    "                feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "    })\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(accuracy, \n",
    "                       feed_dict = {\n",
    "                            x: feature_batch,\n",
    "                            y: label_batch,\n",
    "                            keep_prob: 1.\n",
    "    })\n",
    "    \n",
    "    validation_accuracy = session.run(accuracy, \n",
    "                                      feed_dict={\n",
    "                                            x: valid_features,\n",
    "                                            y: valid_labels,\n",
    "                                            keep_prob: 1.\n",
    "    })\n",
    "    \n",
    "    print('Loss: {} Validation Accuracy: {}'.format(loss, validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 400\n",
    "batch_size = 1024\n",
    "keep_probability = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 0.13118810951709747 Validation Accuracy: 0.14659999310970306\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 0.1868811845779419 Validation Accuracy: 0.20040000975131989\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 0.21163365244865417 Validation Accuracy: 0.21719998121261597\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 0.20668315887451172 Validation Accuracy: 0.2191999852657318\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 0.2326732575893402 Validation Accuracy: 0.2553999722003937\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 0.2759900987148285 Validation Accuracy: 0.267799973487854\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 0.285891056060791 Validation Accuracy: 0.2786000072956085\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 0.2933168411254883 Validation Accuracy: 0.284199982881546\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 0.30074256658554077 Validation Accuracy: 0.27580001950263977\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 0.30074256658554077 Validation Accuracy: 0.2709999978542328\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 0.3143564462661743 Validation Accuracy: 0.29019996523857117\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 0.32301977276802063 Validation Accuracy: 0.2914000153541565\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.31683167815208435 Validation Accuracy: 0.28999996185302734\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 0.3403465151786804 Validation Accuracy: 0.2916000187397003\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.34158414602279663 Validation Accuracy: 0.3107999563217163\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.3564356565475464 Validation Accuracy: 0.3089999854564667\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.3551980257034302 Validation Accuracy: 0.31620001792907715\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.3576732575893402 Validation Accuracy: 0.3190000057220459\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.37128713726997375 Validation Accuracy: 0.32739996910095215\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.38985151052474976 Validation Accuracy: 0.3401999771595001\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.3836633563041687 Validation Accuracy: 0.34759995341300964\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.4009901285171509 Validation Accuracy: 0.3521999716758728\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.4022276997566223 Validation Accuracy: 0.36319997906684875\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.40841585397720337 Validation Accuracy: 0.3669999837875366\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.4009901285171509 Validation Accuracy: 0.3633999824523926\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.4022276997566223 Validation Accuracy: 0.3651999533176422\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.4306930899620056 Validation Accuracy: 0.3797999620437622\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.4195544123649597 Validation Accuracy: 0.38839995861053467\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.42945539951324463 Validation Accuracy: 0.38999998569488525\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.43316829204559326 Validation Accuracy: 0.39399999380111694\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.4368811845779419 Validation Accuracy: 0.39659997820854187\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.44925743341445923 Validation Accuracy: 0.4123999774456024\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.46039605140686035 Validation Accuracy: 0.41519996523857117\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.4455445408821106 Validation Accuracy: 0.4073999524116516\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.4641088843345642 Validation Accuracy: 0.42319995164871216\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.45792075991630554 Validation Accuracy: 0.4074000120162964\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.46039602160453796 Validation Accuracy: 0.4171999990940094\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.4715346097946167 Validation Accuracy: 0.4259999990463257\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.48638612031936646 Validation Accuracy: 0.42640000581741333\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.4975247085094452 Validation Accuracy: 0.43379998207092285\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.4913366436958313 Validation Accuracy: 0.4252000153064728\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.49504944682121277 Validation Accuracy: 0.44040000438690186\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.4925742745399475 Validation Accuracy: 0.43619996309280396\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.498762309551239 Validation Accuracy: 0.43699997663497925\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.49628716707229614 Validation Accuracy: 0.4371999502182007\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.49628710746765137 Validation Accuracy: 0.4376000165939331\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.5049505233764648 Validation Accuracy: 0.4403999447822571\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.4999999701976776 Validation Accuracy: 0.4456000030040741\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.5111385583877563 Validation Accuracy: 0.4365999698638916\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.5148515105247498 Validation Accuracy: 0.44339996576309204\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.5136138200759888 Validation Accuracy: 0.4453999698162079\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.5160890817642212 Validation Accuracy: 0.44839996099472046\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.5198019742965698 Validation Accuracy: 0.45219993591308594\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.5198019742965698 Validation Accuracy: 0.44839996099472046\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.5235148668289185 Validation Accuracy: 0.459199994802475\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.5284653902053833 Validation Accuracy: 0.4625999331474304\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.5396039485931396 Validation Accuracy: 0.45979994535446167\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.5358911156654358 Validation Accuracy: 0.4609999656677246\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.5383663177490234 Validation Accuracy: 0.45819997787475586\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.5358911156654358 Validation Accuracy: 0.4601999521255493\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.5297029614448547 Validation Accuracy: 0.45419996976852417\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.5247524976730347 Validation Accuracy: 0.44359996914863586\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.5259900689125061 Validation Accuracy: 0.44099998474121094\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.5420792102813721 Validation Accuracy: 0.46539998054504395\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.5532177686691284 Validation Accuracy: 0.4591999650001526\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.5495049357414246 Validation Accuracy: 0.4591999650001526\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.5519801378250122 Validation Accuracy: 0.4617999494075775\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.5507425665855408 Validation Accuracy: 0.4607999920845032\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.5581682920455933 Validation Accuracy: 0.46379995346069336\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.5631188154220581 Validation Accuracy: 0.462399959564209\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.5581682920455933 Validation Accuracy: 0.4609999656677246\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.5482673645019531 Validation Accuracy: 0.46279996633529663\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.5581682920455933 Validation Accuracy: 0.4671999216079712\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.5693069100379944 Validation Accuracy: 0.46939995884895325\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.5717821717262268 Validation Accuracy: 0.47499996423721313\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.5643564462661743 Validation Accuracy: 0.47179996967315674\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.5643564462661743 Validation Accuracy: 0.4657999575138092\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.5495049357414246 Validation Accuracy: 0.4603999853134155\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.5544553995132446 Validation Accuracy: 0.4544000029563904\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.5693069696426392 Validation Accuracy: 0.4675999581813812\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.5804455280303955 Validation Accuracy: 0.47519993782043457\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.5705446004867554 Validation Accuracy: 0.4713999927043915\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.5816830992698669 Validation Accuracy: 0.4745999574661255\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.5853960514068604 Validation Accuracy: 0.4819999635219574\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.5841583609580994 Validation Accuracy: 0.4763999581336975\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.5853959918022156 Validation Accuracy: 0.47279995679855347\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.5767326951026917 Validation Accuracy: 0.4697999656200409\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.5841584205627441 Validation Accuracy: 0.4763999581336975\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.5829207897186279 Validation Accuracy: 0.46779996156692505\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.5829207897186279 Validation Accuracy: 0.47259992361068726\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.5866336822509766 Validation Accuracy: 0.4761999547481537\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.5928217768669128 Validation Accuracy: 0.47540000081062317\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.5915840864181519 Validation Accuracy: 0.4763999581336975\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.5952970385551453 Validation Accuracy: 0.47839996218681335\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.5829207897186279 Validation Accuracy: 0.4707999527454376\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.5816831588745117 Validation Accuracy: 0.47039997577667236\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.5977722406387329 Validation Accuracy: 0.4713999330997467\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.5730197429656982 Validation Accuracy: 0.46859994530677795\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.5990098714828491 Validation Accuracy: 0.4745999872684479\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.5891088843345642 Validation Accuracy: 0.47759997844696045\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss: 0.6027227640151978 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss: 0.6064356565475464 Validation Accuracy: 0.48159998655319214\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss: 0.6064355969429016 Validation Accuracy: 0.4821999669075012\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss: 0.6126237511634827 Validation Accuracy: 0.4803999662399292\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss: 0.6150990128517151 Validation Accuracy: 0.48159995675086975\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss: 0.6150989532470703 Validation Accuracy: 0.4843999743461609\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss: 0.6002475023269653 Validation Accuracy: 0.47839993238449097\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss: 0.6237623691558838 Validation Accuracy: 0.4819999635219574\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss: 0.631188154220581 Validation Accuracy: 0.48079997301101685\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss: 0.6175742745399475 Validation Accuracy: 0.4873999357223511\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss: 0.6138613820075989 Validation Accuracy: 0.48399993777275085\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss: 0.6064356565475464 Validation Accuracy: 0.4829999804496765\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss: 0.6324257850646973 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss: 0.6089107990264893 Validation Accuracy: 0.48319995403289795\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss: 0.6188119053840637 Validation Accuracy: 0.4813999533653259\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss: 0.6336633563041687 Validation Accuracy: 0.488599956035614\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss: 0.6150990128517151 Validation Accuracy: 0.4873999059200287\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss: 0.6324257850646973 Validation Accuracy: 0.48259997367858887\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss: 0.6200495362281799 Validation Accuracy: 0.48379990458488464\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss: 0.6299505233764648 Validation Accuracy: 0.47999992966651917\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss: 0.6101484894752502 Validation Accuracy: 0.46839991211891174\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss: 0.6212871074676514 Validation Accuracy: 0.4737999737262726\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss: 0.6175742745399475 Validation Accuracy: 0.48579996824264526\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss: 0.6336632966995239 Validation Accuracy: 0.4851999878883362\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss: 0.6361386179924011 Validation Accuracy: 0.4817999601364136\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss: 0.6349009275436401 Validation Accuracy: 0.4805999994277954\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss: 0.6448019742965698 Validation Accuracy: 0.4869999289512634\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss: 0.6522276997566223 Validation Accuracy: 0.48539999127388\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss: 0.6472772359848022 Validation Accuracy: 0.48539999127388\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss: 0.6435643434524536 Validation Accuracy: 0.48719996213912964\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss: 0.6448019742965698 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss: 0.6386138200759888 Validation Accuracy: 0.48239994049072266\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss: 0.6485148072242737 Validation Accuracy: 0.4857999384403229\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss: 0.639851450920105 Validation Accuracy: 0.4785999357700348\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss: 0.6410890817642212 Validation Accuracy: 0.4813999831676483\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss: 0.6448019742965698 Validation Accuracy: 0.48159998655319214\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss: 0.6633663177490234 Validation Accuracy: 0.4857999384403229\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss: 0.639851450920105 Validation Accuracy: 0.48059993982315063\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss: 0.639851450920105 Validation Accuracy: 0.49199995398521423\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss: 0.6596534252166748 Validation Accuracy: 0.48799997568130493\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss: 0.6745049953460693 Validation Accuracy: 0.4785999655723572\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss: 0.6745049357414246 Validation Accuracy: 0.4901999533176422\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss: 0.6596534252166748 Validation Accuracy: 0.4771999716758728\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss: 0.6707921028137207 Validation Accuracy: 0.48399996757507324\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss: 0.6769802570343018 Validation Accuracy: 0.4785999357700348\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss: 0.6732673048973083 Validation Accuracy: 0.4797999858856201\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss: 0.6806930899620056 Validation Accuracy: 0.4773999750614166\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss: 0.6844059824943542 Validation Accuracy: 0.4827999770641327\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss: 0.6794554591178894 Validation Accuracy: 0.4851999282836914\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss: 0.6745049357414246 Validation Accuracy: 0.48899996280670166\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss: 0.6844059824943542 Validation Accuracy: 0.48539993166923523\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss: 0.6745049953460693 Validation Accuracy: 0.48399996757507324\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss: 0.683168351650238 Validation Accuracy: 0.48879992961883545\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss: 0.683168351650238 Validation Accuracy: 0.48919999599456787\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss: 0.6707921028137207 Validation Accuracy: 0.4919999837875366\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss: 0.6782178282737732 Validation Accuracy: 0.4827999472618103\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss: 0.6745049357414246 Validation Accuracy: 0.4883999526500702\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss: 0.6856436133384705 Validation Accuracy: 0.48659995198249817\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss: 0.676980197429657 Validation Accuracy: 0.48479995131492615\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss: 0.6831682920455933 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss: 0.6658415794372559 Validation Accuracy: 0.4817999303340912\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss: 0.6707920432090759 Validation Accuracy: 0.4795999825000763\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss: 0.6856436133384705 Validation Accuracy: 0.4859999418258667\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss: 0.6943069696426392 Validation Accuracy: 0.49059998989105225\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss: 0.6175742745399475 Validation Accuracy: 0.45719999074935913\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss: 0.6584157943725586 Validation Accuracy: 0.47599995136260986\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss: 0.6868811845779419 Validation Accuracy: 0.49139997363090515\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss: 0.6844059824943542 Validation Accuracy: 0.4833999276161194\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss: 0.6856435537338257 Validation Accuracy: 0.48500001430511475\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss: 0.6905940771102905 Validation Accuracy: 0.49219992756843567\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss: 0.6893564462661743 Validation Accuracy: 0.49239999055862427\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss: 0.6893564462661743 Validation Accuracy: 0.4867999255657196\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss: 0.6967822313308716 Validation Accuracy: 0.483599990606308\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss: 0.7004950642585754 Validation Accuracy: 0.49859991669654846\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss: 0.7116336822509766 Validation Accuracy: 0.49279993772506714\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss: 0.7091584205627441 Validation Accuracy: 0.4907999634742737\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss: 0.6918317675590515 Validation Accuracy: 0.4869999289512634\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss: 0.693069338798523 Validation Accuracy: 0.4893999397754669\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss: 0.7004950642585754 Validation Accuracy: 0.4883999526500702\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss: 0.6943069696426392 Validation Accuracy: 0.47939997911453247\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss: 0.6930692791938782 Validation Accuracy: 0.4809999465942383\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss: 0.698019802570343 Validation Accuracy: 0.486799955368042\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss: 0.7141088843345642 Validation Accuracy: 0.49359995126724243\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss: 0.7004950046539307 Validation Accuracy: 0.48979997634887695\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss: 0.7017326354980469 Validation Accuracy: 0.48739996552467346\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss: 0.7091584205627441 Validation Accuracy: 0.48819997906684875\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss: 0.7066831588745117 Validation Accuracy: 0.49359995126724243\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss: 0.6967821717262268 Validation Accuracy: 0.49119997024536133\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss: 0.7054455280303955 Validation Accuracy: 0.49219992756843567\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss: 0.6955446004867554 Validation Accuracy: 0.48159995675086975\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss: 0.7190593481063843 Validation Accuracy: 0.48399993777275085\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss: 0.7227722406387329 Validation Accuracy: 0.4935999810695648\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss: 0.7190594673156738 Validation Accuracy: 0.4939999580383301\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss: 0.7128713130950928 Validation Accuracy: 0.49459993839263916\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss: 0.7240099310874939 Validation Accuracy: 0.49039995670318604\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss: 0.7128713130950928 Validation Accuracy: 0.4957999587059021\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss: 0.7178218364715576 Validation Accuracy: 0.49199995398521423\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss: 0.7326732277870178 Validation Accuracy: 0.48559996485710144\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss: 0.7079207897186279 Validation Accuracy: 0.48159995675086975\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss: 0.7116336226463318 Validation Accuracy: 0.48239997029304504\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss: 0.7202969789505005 Validation Accuracy: 0.4919999837875366\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss: 0.7042078971862793 Validation Accuracy: 0.49299997091293335\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss: 0.7326732873916626 Validation Accuracy: 0.48959994316101074\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss: 0.728960394859314 Validation Accuracy: 0.4821999669075012\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss: 0.7066831588745117 Validation Accuracy: 0.48100000619888306\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss: 0.728960394859314 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss: 0.7240098714828491 Validation Accuracy: 0.4772000014781952\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss: 0.7240099310874939 Validation Accuracy: 0.48219993710517883\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss: 0.7277227640151978 Validation Accuracy: 0.48419997096061707\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss: 0.7128713130950928 Validation Accuracy: 0.4861999750137329\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss: 0.7017326951026917 Validation Accuracy: 0.4899999499320984\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss: 0.7079207897186279 Validation Accuracy: 0.49059993028640747\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss: 0.7240099310874939 Validation Accuracy: 0.4915999472141266\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss: 0.735148549079895 Validation Accuracy: 0.4935999810695648\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss: 0.7376237511634827 Validation Accuracy: 0.49219995737075806\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss: 0.7202969789505005 Validation Accuracy: 0.48879992961883545\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss: 0.7240099906921387 Validation Accuracy: 0.48979994654655457\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss: 0.735148549079895 Validation Accuracy: 0.48659998178482056\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss: 0.7351484894752502 Validation Accuracy: 0.48719993233680725\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss: 0.7388613224029541 Validation Accuracy: 0.4841999411582947\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss: 0.7438119053840637 Validation Accuracy: 0.4845999479293823\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss: 0.7450494766235352 Validation Accuracy: 0.49359995126724243\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss: 0.7314356565475464 Validation Accuracy: 0.4949999451637268\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss: 0.7363861799240112 Validation Accuracy: 0.49140000343322754\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss: 0.7178217768669128 Validation Accuracy: 0.48799997568130493\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss: 0.7400990724563599 Validation Accuracy: 0.48879992961883545\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss: 0.7376237511634827 Validation Accuracy: 0.4857999384403229\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss: 0.7599009871482849 Validation Accuracy: 0.4925999343395233\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss: 0.7512376308441162 Validation Accuracy: 0.48819994926452637\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss: 0.7512376308441162 Validation Accuracy: 0.4883999526500702\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss: 0.7537128925323486 Validation Accuracy: 0.4869999885559082\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss: 0.7524752616882324 Validation Accuracy: 0.4891999363899231\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss: 0.756188154220581 Validation Accuracy: 0.4899999797344208\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss: 0.7537128925323486 Validation Accuracy: 0.49059998989105225\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss: 0.764851450920105 Validation Accuracy: 0.4939999580383301\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss: 0.7636138200759888 Validation Accuracy: 0.4931999444961548\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss: 0.7599009275436401 Validation Accuracy: 0.4907999336719513\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss: 0.7586633563041687 Validation Accuracy: 0.48899999260902405\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss: 0.7524752616882324 Validation Accuracy: 0.4867999851703644\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss: 0.7450494766235352 Validation Accuracy: 0.48899996280670166\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss: 0.7524752020835876 Validation Accuracy: 0.49219995737075806\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss: 0.7599009871482849 Validation Accuracy: 0.4907999336719513\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss: 0.7722772359848022 Validation Accuracy: 0.4983999729156494\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss: 0.7561880946159363 Validation Accuracy: 0.48959997296333313\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss: 0.7599009871482849 Validation Accuracy: 0.49199995398521423\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss: 0.7475247383117676 Validation Accuracy: 0.4899999499320984\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss: 0.7549505233764648 Validation Accuracy: 0.4887999892234802\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss: 0.7735148668289185 Validation Accuracy: 0.49359995126724243\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss: 0.7438119053840637 Validation Accuracy: 0.4809999465942383\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss: 0.7574257254600525 Validation Accuracy: 0.48559990525245667\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss: 0.7735148668289185 Validation Accuracy: 0.49379992485046387\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss: 0.7735148668289185 Validation Accuracy: 0.48819994926452637\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss: 0.7685643434524536 Validation Accuracy: 0.4851999580860138\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss: 0.7772276997566223 Validation Accuracy: 0.49399998784065247\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss: 0.7735148668289185 Validation Accuracy: 0.493399977684021\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss: 0.7673267722129822 Validation Accuracy: 0.49359995126724243\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss: 0.766089141368866 Validation Accuracy: 0.48779991269111633\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss: 0.7821782827377319 Validation Accuracy: 0.4939999580383301\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss: 0.771039605140686 Validation Accuracy: 0.4933999180793762\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss: 0.7735148072242737 Validation Accuracy: 0.4899999499320984\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss: 0.7821782231330872 Validation Accuracy: 0.49199992418289185\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss: 0.7747524976730347 Validation Accuracy: 0.4909999668598175\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss: 0.7834158539772034 Validation Accuracy: 0.49119997024536133\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss: 0.7722772359848022 Validation Accuracy: 0.4903999865055084\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss: 0.7698019742965698 Validation Accuracy: 0.4837999641895294\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss: 0.756188154220581 Validation Accuracy: 0.4809999465942383\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss: 0.7623761892318726 Validation Accuracy: 0.4857999384403229\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss: 0.7537128925323486 Validation Accuracy: 0.4835999608039856\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss: 0.7673267126083374 Validation Accuracy: 0.48499998450279236\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss: 0.771039605140686 Validation Accuracy: 0.49279993772506714\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss: 0.7363861203193665 Validation Accuracy: 0.4843999743461609\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss: 0.7376238107681274 Validation Accuracy: 0.48499995470046997\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss: 0.7574257254600525 Validation Accuracy: 0.4887999892234802\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss: 0.7561880946159363 Validation Accuracy: 0.4891999661922455\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss: 0.7673267722129822 Validation Accuracy: 0.4875999987125397\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss: 0.7029703855514526 Validation Accuracy: 0.4649999737739563\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss: 0.7821782231330872 Validation Accuracy: 0.4843999743461609\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss: 0.785891056060791 Validation Accuracy: 0.4925999641418457\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss: 0.7834157943725586 Validation Accuracy: 0.48719993233680725\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss: 0.7710396647453308 Validation Accuracy: 0.4821999669075012\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss: 0.7685643434524536 Validation Accuracy: 0.47359994053840637\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss: 0.7933168411254883 Validation Accuracy: 0.4845999479293823\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss: 0.7908415794372559 Validation Accuracy: 0.4845999777317047\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss: 0.7871286869049072 Validation Accuracy: 0.48419997096061707\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss: 0.7920792102813721 Validation Accuracy: 0.48219993710517883\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss: 0.7908415794372559 Validation Accuracy: 0.4787999391555786\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss: 0.7957921624183655 Validation Accuracy: 0.4857999384403229\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss: 0.7883663773536682 Validation Accuracy: 0.4769999384880066\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss: 0.7772276997566223 Validation Accuracy: 0.4787999391555786\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss: 0.7698019742965698 Validation Accuracy: 0.47339993715286255\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss: 0.7586634159088135 Validation Accuracy: 0.47679996490478516\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss: 0.7438119053840637 Validation Accuracy: 0.472199946641922\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss: 0.7450495362281799 Validation Accuracy: 0.4729999601840973\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss: 0.7636138796806335 Validation Accuracy: 0.48079997301101685\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss: 0.7698019742965698 Validation Accuracy: 0.4843999743461609\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss: 0.7735148668289185 Validation Accuracy: 0.4957999587059021\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss: 0.7883663177490234 Validation Accuracy: 0.491599977016449\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss: 0.785891056060791 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss: 0.7660890817642212 Validation Accuracy: 0.4827999472618103\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss: 0.7710396647453308 Validation Accuracy: 0.4801999628543854\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss: 0.7834158539772034 Validation Accuracy: 0.4819999635219574\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss: 0.7871286869049072 Validation Accuracy: 0.4901999533176422\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss: 0.7772276997566223 Validation Accuracy: 0.48659995198249817\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss: 0.785891056060791 Validation Accuracy: 0.48539999127388\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss: 0.7759901285171509 Validation Accuracy: 0.48339998722076416\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss: 0.7809406518936157 Validation Accuracy: 0.4859999716281891\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss: 0.8007425665855408 Validation Accuracy: 0.49219995737075806\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss: 0.8069306015968323 Validation Accuracy: 0.4877999424934387\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss: 0.7957920432090759 Validation Accuracy: 0.48479995131492615\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss: 0.7982673048973083 Validation Accuracy: 0.478799968957901\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss: 0.8094059824943542 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss: 0.8106435537338257 Validation Accuracy: 0.48899996280670166\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss: 0.8118811845779419 Validation Accuracy: 0.48259997367858887\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss: 0.8069307208061218 Validation Accuracy: 0.48399996757507324\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss: 0.7995048761367798 Validation Accuracy: 0.48399996757507324\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss: 0.8118811249732971 Validation Accuracy: 0.4817999601364136\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss: 0.818069338798523 Validation Accuracy: 0.48959997296333313\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss: 0.8279702663421631 Validation Accuracy: 0.4835999608039856\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss: 0.823019802570343 Validation Accuracy: 0.4795999526977539\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss: 0.8193069100379944 Validation Accuracy: 0.4869999587535858\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss: 0.8081682920455933 Validation Accuracy: 0.48499998450279236\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss: 0.8007425665855408 Validation Accuracy: 0.48879995942115784\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss: 0.7797030210494995 Validation Accuracy: 0.4797999858856201\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss: 0.7735148668289185 Validation Accuracy: 0.47939997911453247\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss: 0.7846534252166748 Validation Accuracy: 0.47019994258880615\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss: 0.780940592288971 Validation Accuracy: 0.4745999574661255\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss: 0.8168317079544067 Validation Accuracy: 0.48539999127388\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss: 0.8193069696426392 Validation Accuracy: 0.4865999221801758\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss: 0.8155940175056458 Validation Accuracy: 0.48719996213912964\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss: 0.8106434941291809 Validation Accuracy: 0.48159998655319214\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss: 0.8106435537338257 Validation Accuracy: 0.48159995675086975\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss: 0.8118812441825867 Validation Accuracy: 0.48259997367858887\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss: 0.7957921028137207 Validation Accuracy: 0.4835999608039856\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss: 0.8217821717262268 Validation Accuracy: 0.48479992151260376\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss: 0.8180692791938782 Validation Accuracy: 0.48499998450279236\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss: 0.8205444812774658 Validation Accuracy: 0.4833999574184418\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss: 0.8180692195892334 Validation Accuracy: 0.48499998450279236\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss: 0.8292078971862793 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss: 0.8353960514068604 Validation Accuracy: 0.4845999777317047\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss: 0.839108943939209 Validation Accuracy: 0.4859999418258667\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss: 0.8428218364715576 Validation Accuracy: 0.4821999967098236\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss: 0.8440593481063843 Validation Accuracy: 0.48659998178482056\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss: 0.8391088843345642 Validation Accuracy: 0.4803999662399292\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss: 0.8242573738098145 Validation Accuracy: 0.4849998950958252\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss: 0.8131188154220581 Validation Accuracy: 0.47999992966651917\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss: 0.8378713130950928 Validation Accuracy: 0.4845999777317047\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss: 0.8205444812774658 Validation Accuracy: 0.48879992961883545\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss: 0.8304455280303955 Validation Accuracy: 0.4877999424934387\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss: 0.8292079567909241 Validation Accuracy: 0.4801999628543854\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss: 0.8415841460227966 Validation Accuracy: 0.4785999357700348\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss: 0.8242573738098145 Validation Accuracy: 0.4817999303340912\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss: 0.8131188154220581 Validation Accuracy: 0.4747999310493469\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss: 0.8032177686691284 Validation Accuracy: 0.47760000824928284\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss: 0.821782112121582 Validation Accuracy: 0.4803999364376068\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss: 0.8193069100379944 Validation Accuracy: 0.48159995675086975\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss: 0.8032178282737732 Validation Accuracy: 0.48059993982315063\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss: 0.7970297336578369 Validation Accuracy: 0.47759997844696045\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss: 0.8329207897186279 Validation Accuracy: 0.4817999601364136\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss: 0.8131188154220581 Validation Accuracy: 0.48219993710517883\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss: 0.837871253490448 Validation Accuracy: 0.4829999804496765\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss: 0.8279702663421631 Validation Accuracy: 0.48499995470046997\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss: 0.8180692791938782 Validation Accuracy: 0.478799968957901\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss: 0.8279702663421631 Validation Accuracy: 0.48459991812705994\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss: 0.8131187558174133 Validation Accuracy: 0.4843999147415161\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss: 0.7920792102813721 Validation Accuracy: 0.47659996151924133\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss: 0.8007426261901855 Validation Accuracy: 0.4821999669075012\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss: 0.8081682920455933 Validation Accuracy: 0.48219993710517883\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss: 0.821782112121582 Validation Accuracy: 0.4875999689102173\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss: 0.8279703259468079 Validation Accuracy: 0.487199991941452\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss: 0.8007425665855408 Validation Accuracy: 0.4787999391555786\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss: 0.8267326354980469 Validation Accuracy: 0.48499995470046997\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss: 0.8341583609580994 Validation Accuracy: 0.4869999885559082\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss: 0.8131188750267029 Validation Accuracy: 0.48259997367858887\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss: 0.8242573738098145 Validation Accuracy: 0.48379993438720703\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss: 0.8180692791938782 Validation Accuracy: 0.4805999994277954\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss: 0.8180692791938782 Validation Accuracy: 0.47899994254112244\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss: 0.8292078971862793 Validation Accuracy: 0.4811999201774597\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss: 0.8329207897186279 Validation Accuracy: 0.48059991002082825\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss: 0.8329207897186279 Validation Accuracy: 0.4811999797821045\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss: 0.8366336822509766 Validation Accuracy: 0.48379993438720703\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss: 0.8428217172622681 Validation Accuracy: 0.48379993438720703\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss: 0.8415841460227966 Validation Accuracy: 0.48099997639656067\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss: 0.8353959918022156 Validation Accuracy: 0.48099997639656067\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss: 0.8490098714828491 Validation Accuracy: 0.4869999587535858\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss: 0.8415841460227966 Validation Accuracy: 0.48639997839927673\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss: 0.8502475619316101 Validation Accuracy: 0.4859999418258667\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss: 0.8465346693992615 Validation Accuracy: 0.4851999878883362\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss: 0.8477722406387329 Validation Accuracy: 0.4901999235153198\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss: 0.8576732873916626 Validation Accuracy: 0.47999995946884155\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss: 0.8601484894752502 Validation Accuracy: 0.47439995408058167\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss: 0.8650990128517151 Validation Accuracy: 0.4803999066352844\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss: 0.853960394859314 Validation Accuracy: 0.47679999470710754\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss: 0.8452969789505005 Validation Accuracy: 0.4706000089645386\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss: 0.8527227640151978 Validation Accuracy: 0.48399996757507324\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss: 0.8131188750267029 Validation Accuracy: 0.4813999533653259\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss: 0.821782112121582 Validation Accuracy: 0.4765999913215637\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss: 0.7933167815208435 Validation Accuracy: 0.4691999852657318\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss: 0.8341583609580994 Validation Accuracy: 0.49039995670318604\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss: 0.8452970385551453 Validation Accuracy: 0.4859999418258667\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss: 0.8502475023269653 Validation Accuracy: 0.48319995403289795\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 0.17450496554374695 Validation Accuracy: 0.1735999882221222\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 0.1881188154220581 Validation Accuracy: 0.1876000016927719\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 0.18316832184791565 Validation Accuracy: 0.19519999623298645\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 0.19801980257034302 Validation Accuracy: 0.20079997181892395\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 0.2400990128517151 Validation Accuracy: 0.22040000557899475\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 0.23514851927757263 Validation Accuracy: 0.25999999046325684\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 0.2611386179924011 Validation Accuracy: 0.2709999978542328\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 0.2685643434524536 Validation Accuracy: 0.2789999842643738\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 0.29950493574142456 Validation Accuracy: 0.3003999888896942\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 0.3106435537338257 Validation Accuracy: 0.2995999753475189\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 0.3279702961444855 Validation Accuracy: 0.30559998750686646\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 0.3292079269886017 Validation Accuracy: 0.3190000057220459\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 0.32673269510269165 Validation Accuracy: 0.31519997119903564\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 0.3304455280303955 Validation Accuracy: 0.32899999618530273\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 0.3366336226463318 Validation Accuracy: 0.3343999683856964\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 0.3551979959011078 Validation Accuracy: 0.3385999798774719\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 0.33292078971862793 Validation Accuracy: 0.3409999907016754\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 0.3551979959011078 Validation Accuracy: 0.34779995679855347\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 0.35148513317108154 Validation Accuracy: 0.3527999818325043\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 0.36014851927757263 Validation Accuracy: 0.3449999988079071\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 0.3589108884334564 Validation Accuracy: 0.34999996423721313\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 0.36014851927757263 Validation Accuracy: 0.3587999641895294\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 0.39108914136886597 Validation Accuracy: 0.3685999810695648\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 0.3663366436958313 Validation Accuracy: 0.3653999865055084\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 0.37004950642585754 Validation Accuracy: 0.3733999729156494\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 0.38737621903419495 Validation Accuracy: 0.37119996547698975\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 0.39975249767303467 Validation Accuracy: 0.3811999559402466\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 0.4133663773536682 Validation Accuracy: 0.3885999917984009\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 0.3861386179924011 Validation Accuracy: 0.3869999945163727\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 0.37995046377182007 Validation Accuracy: 0.3905999958515167\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 0.4183168113231659 Validation Accuracy: 0.3941999673843384\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 0.4207921028137207 Validation Accuracy: 0.4031999707221985\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 0.43316829204559326 Validation Accuracy: 0.39659997820854187\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 0.4207920432090759 Validation Accuracy: 0.40619996190071106\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 0.42574256658554077 Validation Accuracy: 0.4092000126838684\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 0.4467821717262268 Validation Accuracy: 0.42179998755455017\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 0.44801977276802063 Validation Accuracy: 0.42899999022483826\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 0.4566831588745117 Validation Accuracy: 0.4203999638557434\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 0.44183167815208435 Validation Accuracy: 0.43699997663497925\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 0.4554455280303955 Validation Accuracy: 0.42739999294281006\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 0.46039602160453796 Validation Accuracy: 0.44699999690055847\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 0.44925740361213684 Validation Accuracy: 0.44999998807907104\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 0.4826732873916626 Validation Accuracy: 0.4381999671459198\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 0.4566831588745117 Validation Accuracy: 0.45139995217323303\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 0.47524750232696533 Validation Accuracy: 0.44359996914863586\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 0.47772273421287537 Validation Accuracy: 0.45399996638298035\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 0.4616336524486542 Validation Accuracy: 0.4583999812602997\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 0.47772273421287537 Validation Accuracy: 0.44899997115135193\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 0.4740098714828491 Validation Accuracy: 0.4609999656677246\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 0.4888613820075989 Validation Accuracy: 0.4567999839782715\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 0.4999999403953552 Validation Accuracy: 0.4652000069618225\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 0.46658411622047424 Validation Accuracy: 0.4721999764442444\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 0.4975247383117676 Validation Accuracy: 0.4633999466896057\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 0.485148549079895 Validation Accuracy: 0.47099995613098145\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 0.5123761892318726 Validation Accuracy: 0.47179993987083435\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 0.5136138200759888 Validation Accuracy: 0.47419995069503784\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 0.4888613820075989 Validation Accuracy: 0.47999998927116394\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 0.4987623393535614 Validation Accuracy: 0.4675999581813812\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 0.5024752616882324 Validation Accuracy: 0.4817999601364136\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 0.5173267126083374 Validation Accuracy: 0.47279995679855347\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.5235148072242737 Validation Accuracy: 0.48159992694854736\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 0.4987623691558838 Validation Accuracy: 0.4853999614715576\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 0.5136138200759888 Validation Accuracy: 0.47759997844696045\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 0.5024752616882324 Validation Accuracy: 0.4869999587535858\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 0.516089141368866 Validation Accuracy: 0.47979995608329773\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 0.5185643434524536 Validation Accuracy: 0.47939997911453247\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 0.5024752020835876 Validation Accuracy: 0.4939999282360077\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 0.5024752616882324 Validation Accuracy: 0.4813999533653259\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 0.5099009275436401 Validation Accuracy: 0.49859994649887085\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 0.5309405326843262 Validation Accuracy: 0.4989999830722809\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.5160890817642212 Validation Accuracy: 0.48799997568130493\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 0.5111386179924011 Validation Accuracy: 0.49779993295669556\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 0.5198019742965698 Validation Accuracy: 0.4883999526500702\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 0.5371286869049072 Validation Accuracy: 0.5011999607086182\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 0.530940592288971 Validation Accuracy: 0.5043999552726746\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.5383663177490234 Validation Accuracy: 0.4965999722480774\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 0.5185643434524536 Validation Accuracy: 0.5061999559402466\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 0.5383663177490234 Validation Accuracy: 0.5001999139785767\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 0.5284653306007385 Validation Accuracy: 0.5049999356269836\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 0.535891056060791 Validation Accuracy: 0.5005999207496643\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.556930661201477 Validation Accuracy: 0.500999927520752\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 0.5074257254600525 Validation Accuracy: 0.5067999362945557\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 0.5495049357414246 Validation Accuracy: 0.5035999417304993\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 0.5408415794372559 Validation Accuracy: 0.5085999369621277\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 0.550742506980896 Validation Accuracy: 0.5137999653816223\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.5532177686691284 Validation Accuracy: 0.5055999755859375\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 0.5371286869049072 Validation Accuracy: 0.5123999714851379\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 0.5581682920455933 Validation Accuracy: 0.5151998996734619\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 0.5396039485931396 Validation Accuracy: 0.5061999559402466\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 0.5556930303573608 Validation Accuracy: 0.5207999348640442\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.5643564462661743 Validation Accuracy: 0.5135999321937561\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 0.535891056060791 Validation Accuracy: 0.5055999755859375\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 0.5544553995132446 Validation Accuracy: 0.5149999856948853\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 0.5507425665855408 Validation Accuracy: 0.5115999579429626\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 0.5643564462661743 Validation Accuracy: 0.521399974822998\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.5606435537338257 Validation Accuracy: 0.5133999586105347\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 0.5396039485931396 Validation Accuracy: 0.5163999199867249\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 0.5643564462661743 Validation Accuracy: 0.5209999084472656\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 0.5643564462661743 Validation Accuracy: 0.5145999193191528\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 0.5655940771102905 Validation Accuracy: 0.5265999436378479\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.571782112121582 Validation Accuracy: 0.5143999457359314\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 0.5457920432090759 Validation Accuracy: 0.5181999206542969\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 0.5519801378250122 Validation Accuracy: 0.5207999348640442\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 0.5594059228897095 Validation Accuracy: 0.5160000324249268\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 0.5643564462661743 Validation Accuracy: 0.5217999219894409\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.5866336822509766 Validation Accuracy: 0.5263999700546265\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 0.5470296740531921 Validation Accuracy: 0.5231999754905701\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 0.566831648349762 Validation Accuracy: 0.5229999423027039\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 0.5668317079544067 Validation Accuracy: 0.5175999999046326\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 0.5742574334144592 Validation Accuracy: 0.5295999050140381\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.5779702663421631 Validation Accuracy: 0.5219998955726624\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 0.5544554591178894 Validation Accuracy: 0.5299999117851257\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 0.5655940771102905 Validation Accuracy: 0.5261999368667603\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 0.5655940175056458 Validation Accuracy: 0.5209999084472656\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 0.5853959918022156 Validation Accuracy: 0.5299999117851257\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.5829207301139832 Validation Accuracy: 0.5197999477386475\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 0.5606435537338257 Validation Accuracy: 0.5305999517440796\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 0.566831648349762 Validation Accuracy: 0.5273999571800232\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 0.5717821717262268 Validation Accuracy: 0.5281999707221985\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 0.5853960514068604 Validation Accuracy: 0.5335999727249146\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.5853959918022156 Validation Accuracy: 0.5255999565124512\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 0.5668317079544067 Validation Accuracy: 0.5277999043464661\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 0.5754950046539307 Validation Accuracy: 0.5267999172210693\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 0.5730197429656982 Validation Accuracy: 0.5217999815940857\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 0.5829207897186279 Validation Accuracy: 0.5379999279975891\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.5767326951026917 Validation Accuracy: 0.527999997138977\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 0.566831648349762 Validation Accuracy: 0.5321999192237854\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 0.5705445408821106 Validation Accuracy: 0.5313999652862549\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 0.5767326354980469 Validation Accuracy: 0.5333999395370483\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 0.5853960514068604 Validation Accuracy: 0.5345999002456665\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.5878711938858032 Validation Accuracy: 0.5305999517440796\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 0.5680692791938782 Validation Accuracy: 0.5373998880386353\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.5804455280303955 Validation Accuracy: 0.5381999015808105\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 0.5804455280303955 Validation Accuracy: 0.531999945640564\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 0.5915841460227966 Validation Accuracy: 0.5379999279975891\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.5952969789505005 Validation Accuracy: 0.5297999382019043\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 0.5767326354980469 Validation Accuracy: 0.5413999557495117\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.5804455280303955 Validation Accuracy: 0.5371999740600586\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.5792078971862793 Validation Accuracy: 0.5357999205589294\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 0.5965346097946167 Validation Accuracy: 0.5401999354362488\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.5878713130950928 Validation Accuracy: 0.5301999449729919\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 0.5878713130950928 Validation Accuracy: 0.5413998961448669\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.5816831588745117 Validation Accuracy: 0.5357999801635742\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.5829207897186279 Validation Accuracy: 0.5313999056816101\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.5903464555740356 Validation Accuracy: 0.5397999286651611\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.6014851331710815 Validation Accuracy: 0.5341999530792236\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 0.571782112121582 Validation Accuracy: 0.53739994764328\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.587871253490448 Validation Accuracy: 0.539199948310852\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.5940593481063843 Validation Accuracy: 0.5333999395370483\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.5915841460227966 Validation Accuracy: 0.5435999631881714\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.6051980257034302 Validation Accuracy: 0.5327999591827393\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.5841584205627441 Validation Accuracy: 0.5417999625205994\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.587871253490448 Validation Accuracy: 0.5425999164581299\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.5965346097946167 Validation Accuracy: 0.5349999666213989\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.5903465151786804 Validation Accuracy: 0.5461999177932739\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.5965346097946167 Validation Accuracy: 0.5465999245643616\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.5829207301139832 Validation Accuracy: 0.5361999273300171\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.5754950046539307 Validation Accuracy: 0.5441999435424805\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.6002475023269653 Validation Accuracy: 0.5393999218940735\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.5928217768669128 Validation Accuracy: 0.5491999387741089\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.5891088247299194 Validation Accuracy: 0.5423999428749084\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.5965346693992615 Validation Accuracy: 0.5465999245643616\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.5829207897186279 Validation Accuracy: 0.5497999787330627\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.610148549079895 Validation Accuracy: 0.5483999252319336\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.6014850735664368 Validation Accuracy: 0.5535999536514282\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.5977723002433777 Validation Accuracy: 0.5473999381065369\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.5866336822509766 Validation Accuracy: 0.5399999618530273\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.5903465747833252 Validation Accuracy: 0.5495999455451965\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.6039603352546692 Validation Accuracy: 0.542199969291687\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.6051980257034302 Validation Accuracy: 0.5491999387741089\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.602722704410553 Validation Accuracy: 0.5489999055862427\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.6014851331710815 Validation Accuracy: 0.5481999516487122\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.5915841460227966 Validation Accuracy: 0.5509999394416809\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.608910858631134 Validation Accuracy: 0.5475999116897583\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.6150989532470703 Validation Accuracy: 0.5571999549865723\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.6039603352546692 Validation Accuracy: 0.5453999638557434\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 0.5915841460227966 Validation Accuracy: 0.5469999313354492\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 0.5952970385551453 Validation Accuracy: 0.5535998940467834\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 0.6175742745399475 Validation Accuracy: 0.5425999760627747\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 0.6175742745399475 Validation Accuracy: 0.5567999482154846\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.6101484894752502 Validation Accuracy: 0.5419999361038208\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 0.5928217768669128 Validation Accuracy: 0.5473998785018921\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 0.5829207897186279 Validation Accuracy: 0.5443999171257019\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 0.625 Validation Accuracy: 0.5527999401092529\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 0.6237624287605286 Validation Accuracy: 0.5613999366760254\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.6051980257034302 Validation Accuracy: 0.5453999042510986\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 0.6051979660987854 Validation Accuracy: 0.5565999746322632\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 0.589108943939209 Validation Accuracy: 0.5541999340057373\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 0.6200494766235352 Validation Accuracy: 0.5553998947143555\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 0.6126238107681274 Validation Accuracy: 0.5607999563217163\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.608910858631134 Validation Accuracy: 0.5483999252319336\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 0.6126237511634827 Validation Accuracy: 0.5557999014854431\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 0.6027227640151978 Validation Accuracy: 0.5579999089241028\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 0.6324257850646973 Validation Accuracy: 0.5557999014854431\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 0.6287128329277039 Validation Accuracy: 0.5579999089241028\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.6138613224029541 Validation Accuracy: 0.5565999150276184\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 0.6175742149353027 Validation Accuracy: 0.5547999739646912\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 0.6014851331710815 Validation Accuracy: 0.5561999082565308\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 0.6311880946159363 Validation Accuracy: 0.5583999156951904\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 0.6361385583877563 Validation Accuracy: 0.5649999380111694\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.5940593481063843 Validation Accuracy: 0.5541999340057373\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 0.6138614416122437 Validation Accuracy: 0.5527999401092529\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 0.6039603352546692 Validation Accuracy: 0.5555999279022217\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 0.6262376308441162 Validation Accuracy: 0.5549999475479126\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 0.6349009275436401 Validation Accuracy: 0.5587999224662781\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.6212871074676514 Validation Accuracy: 0.5553999543190002\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.6225246787071228 Validation Accuracy: 0.5531999468803406\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.5977722406387329 Validation Accuracy: 0.559999942779541\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.6373762488365173 Validation Accuracy: 0.5627999305725098\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.625 Validation Accuracy: 0.56659996509552\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.6126237511634827 Validation Accuracy: 0.5603999495506287\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.6225247383117676 Validation Accuracy: 0.5529999732971191\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.610148549079895 Validation Accuracy: 0.5607999563217163\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.6361386775970459 Validation Accuracy: 0.5659999251365662\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.639851450920105 Validation Accuracy: 0.5653998851776123\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.6076732277870178 Validation Accuracy: 0.5571998953819275\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.6113861203193665 Validation Accuracy: 0.5451999306678772\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.5965346693992615 Validation Accuracy: 0.5573999285697937\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.6448019742965698 Validation Accuracy: 0.5619999766349792\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.6262376308441162 Validation Accuracy: 0.5583999156951904\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.6101484894752502 Validation Accuracy: 0.5555999279022217\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.6089109182357788 Validation Accuracy: 0.5417999625205994\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.5965346693992615 Validation Accuracy: 0.5587999820709229\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.6262376308441162 Validation Accuracy: 0.5543999671936035\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.6237623691558838 Validation Accuracy: 0.5663999319076538\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.6101484298706055 Validation Accuracy: 0.5695999264717102\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.6274752616882324 Validation Accuracy: 0.5643999576568604\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.608910858631134 Validation Accuracy: 0.5613999366760254\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.6398515105247498 Validation Accuracy: 0.5691999197006226\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.6509900689125061 Validation Accuracy: 0.5669999122619629\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.617574155330658 Validation Accuracy: 0.5679998993873596\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.6262375712394714 Validation Accuracy: 0.5573998689651489\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.6150989532470703 Validation Accuracy: 0.5679998993873596\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.6386138796806335 Validation Accuracy: 0.5641999244689941\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.646039605140686 Validation Accuracy: 0.562999963760376\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.6163365840911865 Validation Accuracy: 0.5635999441146851\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.6237623691558838 Validation Accuracy: 0.5547999143600464\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.6225247383117676 Validation Accuracy: 0.5675999522209167\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.6386139392852783 Validation Accuracy: 0.5631999373435974\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.6460395455360413 Validation Accuracy: 0.5713999271392822\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.6225247383117676 Validation Accuracy: 0.5661999583244324\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.639851450920105 Validation Accuracy: 0.5587999820709229\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.6262376308441162 Validation Accuracy: 0.5663999319076538\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.6311880946159363 Validation Accuracy: 0.5583999752998352\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.6225247383117676 Validation Accuracy: 0.5685999393463135\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.6212871670722961 Validation Accuracy: 0.5663999319076538\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.6299504637718201 Validation Accuracy: 0.5637999773025513\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.6237623691558838 Validation Accuracy: 0.5713999271392822\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.6299505233764648 Validation Accuracy: 0.5633999109268188\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.6398515105247498 Validation Accuracy: 0.5673999190330505\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.6274752616882324 Validation Accuracy: 0.5653999447822571\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 0.6386138200759888 Validation Accuracy: 0.5615999698638916\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 0.6175742149353027 Validation Accuracy: 0.5637999773025513\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 0.6497524380683899 Validation Accuracy: 0.5709999203681946\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 0.6336633563041687 Validation Accuracy: 0.5667999386787415\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.6311880946159363 Validation Accuracy: 0.5713999271392822\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 0.6113861203193665 Validation Accuracy: 0.5561999678611755\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 0.6262376308441162 Validation Accuracy: 0.5695998668670654\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 0.6373762488365173 Validation Accuracy: 0.564599871635437\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 0.646039605140686 Validation Accuracy: 0.5651999115943909\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.6311880350112915 Validation Accuracy: 0.5683999061584473\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 0.6163365840911865 Validation Accuracy: 0.5633999109268188\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 0.6101484894752502 Validation Accuracy: 0.5683999061584473\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 0.6497524976730347 Validation Accuracy: 0.5657999515533447\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 0.6485148668289185 Validation Accuracy: 0.5627999305725098\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.6373761892318726 Validation Accuracy: 0.5583999156951904\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 0.6547029614448547 Validation Accuracy: 0.567599892616272\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 0.618811845779419 Validation Accuracy: 0.5705999135971069\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.6423267126083374 Validation Accuracy: 0.5609999299049377\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 0.655940592288971 Validation Accuracy: 0.5657998919487\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.6349009871482849 Validation Accuracy: 0.5585999488830566\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 0.6299505233764648 Validation Accuracy: 0.5691999197006226\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 0.6299504637718201 Validation Accuracy: 0.571199893951416\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.647277295589447 Validation Accuracy: 0.5583999156951904\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 0.6658415794372559 Validation Accuracy: 0.5717999339103699\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.6336633563041687 Validation Accuracy: 0.5659999251365662\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 0.6287128329277039 Validation Accuracy: 0.5727999210357666\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 0.6324257254600525 Validation Accuracy: 0.5725999474525452\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.646039605140686 Validation Accuracy: 0.5577999353408813\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 0.6435643434524536 Validation Accuracy: 0.5679999589920044\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.6386138200759888 Validation Accuracy: 0.5707998871803284\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 0.6423267722129822 Validation Accuracy: 0.5745999217033386\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.6386138200759888 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.6571782231330872 Validation Accuracy: 0.5659999251365662\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 0.6584158539772034 Validation Accuracy: 0.5653999447822571\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.6386138200759888 Validation Accuracy: 0.5779999494552612\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 0.6311880946159363 Validation Accuracy: 0.574999988079071\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.6324256658554077 Validation Accuracy: 0.5755999684333801\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.655940592288971 Validation Accuracy: 0.5687999129295349\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 0.6547029614448547 Validation Accuracy: 0.5573999285697937\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.6361386179924011 Validation Accuracy: 0.5643998980522156\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 0.6448019742965698 Validation Accuracy: 0.5731999278068542\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.6225247383117676 Validation Accuracy: 0.5811998844146729\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.6509901285171509 Validation Accuracy: 0.5727999210357666\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 0.6534653306007385 Validation Accuracy: 0.5695999264717102\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.6410890817642212 Validation Accuracy: 0.5653998851776123\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.6485148668289185 Validation Accuracy: 0.5679998993873596\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.6299504637718201 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.6559405326843262 Validation Accuracy: 0.567599892616272\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 0.6509901285171509 Validation Accuracy: 0.5743998885154724\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.6435643434524536 Validation Accuracy: 0.5703999400138855\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 0.6423267126083374 Validation Accuracy: 0.5673999786376953\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 0.6287128329277039 Validation Accuracy: 0.5677999258041382\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 0.6621286869049072 Validation Accuracy: 0.5725998878479004\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 0.6547030210494995 Validation Accuracy: 0.5733999013900757\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.6472772359848022 Validation Accuracy: 0.5709999203681946\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 0.6435643434524536 Validation Accuracy: 0.569399893283844\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 0.6349009871482849 Validation Accuracy: 0.5759999752044678\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 0.6509901881217957 Validation Accuracy: 0.5801998972892761\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 0.6584158539772034 Validation Accuracy: 0.5699999332427979\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.6448019742965698 Validation Accuracy: 0.5693999528884888\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 0.6534653306007385 Validation Accuracy: 0.5739998817443848\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 0.6349009871482849 Validation Accuracy: 0.5775999426841736\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 0.6646039485931396 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 0.6670792698860168 Validation Accuracy: 0.5719998478889465\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.6423267126083374 Validation Accuracy: 0.5695999264717102\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 0.660891056060791 Validation Accuracy: 0.5763999223709106\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 0.6460395455360413 Validation Accuracy: 0.582599937915802\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 0.6633663773536682 Validation Accuracy: 0.5753999352455139\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 0.6732673048973083 Validation Accuracy: 0.5763999223709106\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.6509900689125061 Validation Accuracy: 0.5717999339103699\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 0.646039605140686 Validation Accuracy: 0.5693999528884888\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 0.6423267126083374 Validation Accuracy: 0.58079993724823\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 0.6683168411254883 Validation Accuracy: 0.5791999697685242\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 0.6683167815208435 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss: 0.6534653306007385 Validation Accuracy: 0.577799916267395\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss: 0.6472772359848022 Validation Accuracy: 0.5731999278068542\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss: 0.6448019742965698 Validation Accuracy: 0.5797999501228333\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss: 0.6571782231330872 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss: 0.681930661201477 Validation Accuracy: 0.5753999948501587\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss: 0.6534652709960938 Validation Accuracy: 0.5709999799728394\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss: 0.6509900689125061 Validation Accuracy: 0.5733999013900757\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss: 0.6472772359848022 Validation Accuracy: 0.579599916934967\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss: 0.6732673645019531 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss: 0.6782178282737732 Validation Accuracy: 0.574199914932251\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss: 0.6584157943725586 Validation Accuracy: 0.5771999955177307\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss: 0.6497524976730347 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss: 0.6547029614448547 Validation Accuracy: 0.5831999778747559\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss: 0.6769802570343018 Validation Accuracy: 0.5745999217033386\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss: 0.6831684112548828 Validation Accuracy: 0.5785999298095703\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss: 0.6584157943725586 Validation Accuracy: 0.5775999426841736\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss: 0.660891056060791 Validation Accuracy: 0.5743998885154724\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss: 0.6522276997566223 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss: 0.676980197429657 Validation Accuracy: 0.5787999033927917\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss: 0.6856435537338257 Validation Accuracy: 0.5737999081611633\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss: 0.6670792102813721 Validation Accuracy: 0.5775999426841736\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss: 0.6695544719696045 Validation Accuracy: 0.5783999562263489\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss: 0.6571782231330872 Validation Accuracy: 0.5835999846458435\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss: 0.6794554591178894 Validation Accuracy: 0.5809999108314514\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss: 0.6806930303573608 Validation Accuracy: 0.5725999474525452\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss: 0.6559405326843262 Validation Accuracy: 0.5767999291419983\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss: 0.6571782231330872 Validation Accuracy: 0.5781999230384827\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss: 0.6621286869049072 Validation Accuracy: 0.5853999257087708\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss: 0.6757426261901855 Validation Accuracy: 0.5815998911857605\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss: 0.6868811845779419 Validation Accuracy: 0.5753999352455139\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss: 0.6658415198326111 Validation Accuracy: 0.5801998972892761\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss: 0.6695544719696045 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss: 0.6683167815208435 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss: 0.6819307208061218 Validation Accuracy: 0.5721999406814575\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss: 0.6918317675590515 Validation Accuracy: 0.5779998898506165\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss: 0.6670792102813721 Validation Accuracy: 0.5733999013900757\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss: 0.6745049953460693 Validation Accuracy: 0.5781999230384827\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss: 0.6608911156654358 Validation Accuracy: 0.5895999670028687\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss: 0.6844059824943542 Validation Accuracy: 0.5811999440193176\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss: 0.6856436133384705 Validation Accuracy: 0.5733999609947205\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss: 0.6707919836044312 Validation Accuracy: 0.5761999487876892\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss: 0.6571781635284424 Validation Accuracy: 0.5817998647689819\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss: 0.6658415198326111 Validation Accuracy: 0.5839998722076416\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss: 0.6930692791938782 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss: 0.6918317079544067 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss: 0.6732673048973083 Validation Accuracy: 0.5767999887466431\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss: 0.6633663773536682 Validation Accuracy: 0.5811999440193176\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss: 0.6806930303573608 Validation Accuracy: 0.586199939250946\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss: 0.6868811845779419 Validation Accuracy: 0.5765999555587769\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss: 0.6881188154220581 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss: 0.6596534252166748 Validation Accuracy: 0.577799916267395\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss: 0.6782178282737732 Validation Accuracy: 0.5773999691009521\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss: 0.6670792102813721 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss: 0.6868811845779419 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss: 0.6856436133384705 Validation Accuracy: 0.5747998952865601\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss: 0.6707921028137207 Validation Accuracy: 0.5785999298095703\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss: 0.6522276401519775 Validation Accuracy: 0.566399872303009\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss: 0.646039605140686 Validation Accuracy: 0.5773999691009521\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss: 0.698019802570343 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss: 0.6844059228897095 Validation Accuracy: 0.5870000123977661\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss: 0.6695544719696045 Validation Accuracy: 0.5825998783111572\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss: 0.6522276997566223 Validation Accuracy: 0.5749999284744263\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss: 0.6509901285171509 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss: 0.6893565058708191 Validation Accuracy: 0.5753998756408691\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss: 0.6955445408821106 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss: 0.6707920432090759 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss: 0.6831682920455933 Validation Accuracy: 0.5781998634338379\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss: 0.655940592288971 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss: 0.6856435537338257 Validation Accuracy: 0.5747999548912048\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss: 0.6943069696426392 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss: 0.6695544123649597 Validation Accuracy: 0.587199866771698\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss: 0.6720297336578369 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss: 0.6658415198326111 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss: 0.7091584205627441 Validation Accuracy: 0.5805999040603638\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss: 0.6893564462661743 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss: 0.6658415794372559 Validation Accuracy: 0.590199887752533\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss: 0.6745049953460693 Validation Accuracy: 0.5793998837471008\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss: 0.6534652709960938 Validation Accuracy: 0.5863999724388123\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss: 0.7017326951026917 Validation Accuracy: 0.5769999027252197\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss: 0.7042078971862793 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss: 0.6695544123649597 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss: 0.6732673645019531 Validation Accuracy: 0.5815998911857605\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss: 0.65470290184021 Validation Accuracy: 0.5859999656677246\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss: 0.7066831588745117 Validation Accuracy: 0.5801998972892761\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss: 0.7042078375816345 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss: 0.675742506980896 Validation Accuracy: 0.5911999344825745\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss: 0.6584157943725586 Validation Accuracy: 0.5803998708724976\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss: 0.6497524380683899 Validation Accuracy: 0.5859999656677246\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss: 0.6992573738098145 Validation Accuracy: 0.5751999616622925\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss: 0.6943069100379944 Validation Accuracy: 0.5895999073982239\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss: 0.6856435537338257 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss: 0.6670792102813721 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss: 0.6658415198326111 Validation Accuracy: 0.5843998789787292\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss: 0.6955445408821106 Validation Accuracy: 0.5739998817443848\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss: 0.7091584205627441 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss: 0.6757425665855408 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss: 0.660891056060791 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss: 0.6658415794372559 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss: 0.6881187558174133 Validation Accuracy: 0.5723998546600342\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss: 0.7042078971862793 Validation Accuracy: 0.5917998552322388\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss: 0.6794554591178894 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss: 0.6695544719696045 Validation Accuracy: 0.5781998634338379\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss: 0.681930661201477 Validation Accuracy: 0.5853999257087708\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss: 0.6918317079544067 Validation Accuracy: 0.5749999284744263\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss: 0.7054455876350403 Validation Accuracy: 0.5855998992919922\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss: 0.6732673645019531 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss: 0.6584157943725586 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss: 0.6683168411254883 Validation Accuracy: 0.5801998972892761\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss: 0.6918317079544067 Validation Accuracy: 0.5749999284744263\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss: 0.675742506980896 Validation Accuracy: 0.5769999623298645\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss: 0.6782178282737732 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss: 0.6806930899620056 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss: 0.6720296740531921 Validation Accuracy: 0.5757999420166016\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss: 0.7054455876350403 Validation Accuracy: 0.5847999453544617\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss: 0.6893564462661743 Validation Accuracy: 0.584399938583374\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss: 0.6881188750267029 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss: 0.6992574334144592 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss: 0.6745049357414246 Validation Accuracy: 0.5773999094963074\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss: 0.7165840864181519 Validation Accuracy: 0.5835999250411987\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss: 0.7054454684257507 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss: 0.6881188154220581 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss: 0.6930692791938782 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss: 0.6720297336578369 Validation Accuracy: 0.5775998830795288\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss: 0.719059407711029 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss: 0.7017326354980469 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss: 0.6967822313308716 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss: 0.6918317079544067 Validation Accuracy: 0.587399959564209\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss: 0.6806930899620056 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss: 0.712871253490448 Validation Accuracy: 0.582399845123291\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss: 0.6992574334144592 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss: 0.6955446004867554 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss: 0.6943069100379944 Validation Accuracy: 0.5885998606681824\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss: 0.6745049357414246 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss: 0.7141088843345642 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss: 0.7042078971862793 Validation Accuracy: 0.5877999067306519\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss: 0.6905940771102905 Validation Accuracy: 0.5893998742103577\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss: 0.683168351650238 Validation Accuracy: 0.5801999568939209\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss: 0.6881188154220581 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss: 0.7091583609580994 Validation Accuracy: 0.5849999189376831\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss: 0.719059407711029 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss: 0.698019802570343 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss: 0.6868811845779419 Validation Accuracy: 0.585599958896637\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss: 0.6806930303573608 Validation Accuracy: 0.5925998687744141\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss: 0.7091584205627441 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss: 0.7240099310874939 Validation Accuracy: 0.591999888420105\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss: 0.6918317079544067 Validation Accuracy: 0.5903999209403992\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss: 0.6856435537338257 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss: 0.6881188154220581 Validation Accuracy: 0.5839999318122864\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss: 0.714108943939209 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss: 0.7054455876350403 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss: 0.6967821717262268 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss: 0.690593957901001 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss: 0.683168351650238 Validation Accuracy: 0.5833998918533325\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss: 0.7103960514068604 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss: 0.712871253490448 Validation Accuracy: 0.5937999486923218\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss: 0.7054455280303955 Validation Accuracy: 0.5933999419212341\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss: 0.7042078971862793 Validation Accuracy: 0.5919999480247498\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss: 0.6856435537338257 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss: 0.7215346693992615 Validation Accuracy: 0.5881999731063843\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss: 0.7227722406387329 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss: 0.6918317079544067 Validation Accuracy: 0.590999960899353\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss: 0.7103960514068604 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss: 0.6769801378250122 Validation Accuracy: 0.5789998769760132\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss: 0.7029703259468079 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss: 0.7103960514068604 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss: 0.6992573738098145 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss: 0.6992574334144592 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss: 0.6943069100379944 Validation Accuracy: 0.5849999189376831\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss: 0.7116336822509766 Validation Accuracy: 0.5767999291419983\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss: 0.7215346693992615 Validation Accuracy: 0.586199939250946\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss: 0.7066831588745117 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss: 0.7165841460227966 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss: 0.7004950046539307 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss: 0.7165841460227966 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss: 0.7202969789505005 Validation Accuracy: 0.5879998803138733\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss: 0.690593957901001 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss: 0.7103960514068604 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss: 0.6918317079544067 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss: 0.7252475023269653 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss: 0.7054455280303955 Validation Accuracy: 0.582599937915802\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss: 0.6868812441825867 Validation Accuracy: 0.5821998715400696\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss: 0.7178218364715576 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss: 0.7042078971862793 Validation Accuracy: 0.5877999067306519\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss: 0.7264851331710815 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss: 0.7153465747833252 Validation Accuracy: 0.5745999813079834\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss: 0.7004950046539307 Validation Accuracy: 0.590199887752533\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss: 0.7042078971862793 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss: 0.7004950642585754 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss: 0.7227722406387329 Validation Accuracy: 0.5917999148368835\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss: 0.7141088843345642 Validation Accuracy: 0.5789999961853027\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss: 0.6856435537338257 Validation Accuracy: 0.5825999975204468\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss: 0.7128713130950928 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss: 0.7017326951026917 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss: 0.7215346097946167 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss: 0.7153465747833252 Validation Accuracy: 0.5761999487876892\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss: 0.699257493019104 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss: 0.7190594673156738 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss: 0.6893564462661743 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss: 0.7413365840911865 Validation Accuracy: 0.5937999486923218\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss: 0.7153465151786804 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss: 0.6918317079544067 Validation Accuracy: 0.5849999189376831\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss: 0.7153465747833252 Validation Accuracy: 0.5895999073982239\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss: 0.6955445408821106 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss: 0.735148549079895 Validation Accuracy: 0.5905999541282654\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss: 0.7202970385551453 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss: 0.6967822313308716 Validation Accuracy: 0.5819998979568481\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss: 0.719059407711029 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss: 0.7029703259468079 Validation Accuracy: 0.5875998735427856\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss: 0.7363861203193665 Validation Accuracy: 0.5951999425888062\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss: 0.7165841460227966 Validation Accuracy: 0.5775998830795288\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss: 0.693069338798523 Validation Accuracy: 0.5839998722076416\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss: 0.7178217768669128 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss: 0.7042079567909241 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss: 0.7400990128517151 Validation Accuracy: 0.5875998735427856\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss: 0.714108943939209 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss: 0.6881188154220581 Validation Accuracy: 0.5777999758720398\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss: 0.7165841460227966 Validation Accuracy: 0.5929998755455017\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss: 0.693069338798523 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss: 0.714108943939209 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss: 0.7054455280303955 Validation Accuracy: 0.5797999501228333\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss: 0.7103960514068604 Validation Accuracy: 0.5915998816490173\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss: 0.6868811845779419 Validation Accuracy: 0.5779999494552612\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss: 0.7029703259468079 Validation Accuracy: 0.5991999506950378\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss: 0.7400990128517151 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss: 0.7314356565475464 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss: 0.7128713130950928 Validation Accuracy: 0.5945999026298523\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss: 0.7004950642585754 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss: 0.6992574334144592 Validation Accuracy: 0.5937999486923218\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss: 0.7363861203193665 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss: 0.7301980257034302 Validation Accuracy: 0.592799961566925\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss: 0.7202969789505005 Validation Accuracy: 0.5897998809814453\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss: 0.6918317079544067 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss: 0.6992574334144592 Validation Accuracy: 0.592799961566925\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss: 0.7178218364715576 Validation Accuracy: 0.5865998864173889\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss: 0.728960394859314 Validation Accuracy: 0.5875998735427856\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss: 0.7264851331710815 Validation Accuracy: 0.5999999046325684\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss: 0.7029702067375183 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss: 0.7091584205627441 Validation Accuracy: 0.5919999480247498\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss: 0.7339109182357788 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss: 0.7277228236198425 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss: 0.7264851331710815 Validation Accuracy: 0.5929998755455017\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss: 0.7153465151786804 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss: 0.7066831588745117 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss: 0.7376237511634827 Validation Accuracy: 0.5851999521255493\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss: 0.7277228236198425 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss: 0.7264851331710815 Validation Accuracy: 0.5953999161720276\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss: 0.7202969789505005 Validation Accuracy: 0.5923999547958374\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss: 0.7079207897186279 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss: 0.7351484894752502 Validation Accuracy: 0.5917998552322388\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss: 0.728960394859314 Validation Accuracy: 0.5871999859809875\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss: 0.7289604544639587 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss: 0.7215346693992615 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss: 0.7128713130950928 Validation Accuracy: 0.5895999073982239\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss: 0.7376237511634827 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss: 0.7252475619316101 Validation Accuracy: 0.5863999724388123\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss: 0.7301980257034302 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss: 0.7178217768669128 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss: 0.7066832184791565 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss: 0.7376237511634827 Validation Accuracy: 0.5851999521255493\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss: 0.7326732873916626 Validation Accuracy: 0.5919999480247498\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss: 0.7252475619316101 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss: 0.7264851331710815 Validation Accuracy: 0.5923999547958374\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss: 0.7029703259468079 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss: 0.733910858631134 Validation Accuracy: 0.5815998911857605\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss: 0.7376237511634827 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss: 0.7326732873916626 Validation Accuracy: 0.5947999358177185\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss: 0.7215346693992615 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss: 0.714108943939209 Validation Accuracy: 0.5895998477935791\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss: 0.7400990128517151 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss: 0.7400990724563599 Validation Accuracy: 0.5905999541282654\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss: 0.7091584205627441 Validation Accuracy: 0.5949999094009399\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss: 0.7066830992698669 Validation Accuracy: 0.584399938583374\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss: 0.7178218364715576 Validation Accuracy: 0.5995998978614807\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss: 0.7537128925323486 Validation Accuracy: 0.5935999155044556\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss: 0.7425742745399475 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss: 0.72029709815979 Validation Accuracy: 0.5971998572349548\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss: 0.7042078971862793 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss: 0.714108943939209 Validation Accuracy: 0.6007999181747437\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss: 0.7450494766235352 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss: 0.7277228236198425 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss: 0.7240098714828491 Validation Accuracy: 0.597399890422821\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss: 0.7215346097946167 Validation Accuracy: 0.590399980545044\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss: 0.7066831588745117 Validation Accuracy: 0.5983999371528625\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss: 0.7413365840911865 Validation Accuracy: 0.5849999189376831\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss: 0.7252475619316101 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss: 0.7314356565475464 Validation Accuracy: 0.5961999297142029\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss: 0.7264851331710815 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss: 0.7277227640151978 Validation Accuracy: 0.6015998721122742\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss: 0.75 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss: 0.7314356565475464 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss: 0.7289604544639587 Validation Accuracy: 0.5981999039649963\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss: 0.728960394859314 Validation Accuracy: 0.5989998579025269\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss: 0.7326733469963074 Validation Accuracy: 0.600399911403656\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss: 0.75 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss: 0.7227722406387329 Validation Accuracy: 0.5819999575614929\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss: 0.7363861203193665 Validation Accuracy: 0.5997999906539917\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss: 0.7301980257034302 Validation Accuracy: 0.5953999161720276\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss: 0.7314356565475464 Validation Accuracy: 0.6041998863220215\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss: 0.7462871670722961 Validation Accuracy: 0.5983998775482178\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss: 0.7301980257034302 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss: 0.7339109182357788 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss: 0.7301980257034302 Validation Accuracy: 0.5895999670028687\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss: 0.7376237511634827 Validation Accuracy: 0.6025999188423157\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss: 0.7549505233764648 Validation Accuracy: 0.5983998775482178\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss: 0.72029709815979 Validation Accuracy: 0.5797998905181885\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss: 0.7215346097946167 Validation Accuracy: 0.5999999046325684\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss: 0.7165842056274414 Validation Accuracy: 0.589199960231781\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss: 0.7165842056274414 Validation Accuracy: 0.6017999649047852\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss: 0.7450495362281799 Validation Accuracy: 0.5983999371528625\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss: 0.7240099310874939 Validation Accuracy: 0.5665999054908752\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss: 0.7128713726997375 Validation Accuracy: 0.5917999744415283\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss: 0.7425742745399475 Validation Accuracy: 0.5939999222755432\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss: 0.7227722406387329 Validation Accuracy: 0.5959998965263367\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss: 0.7400990128517151 Validation Accuracy: 0.5965999960899353\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss: 0.7277227640151978 Validation Accuracy: 0.5739999413490295\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss: 0.7190594673156738 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss: 0.7227723002433777 Validation Accuracy: 0.5877999067306519\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss: 0.7240099310874939 Validation Accuracy: 0.5951998829841614\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss: 0.7475247383117676 Validation Accuracy: 0.593799889087677\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss: 0.7264851927757263 Validation Accuracy: 0.578999936580658\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss: 0.7116337418556213 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss: 0.719059407711029 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss: 0.7227723002433777 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss: 0.7425743341445923 Validation Accuracy: 0.598599910736084\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss: 0.743811845779419 Validation Accuracy: 0.5869999527931213\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss: 0.7103960514068604 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss: 0.7227723002433777 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss: 0.7227723002433777 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss: 0.7351484894752502 Validation Accuracy: 0.5991999506950378\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss: 0.7450495362281799 Validation Accuracy: 0.5899999737739563\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss: 0.7190593481063843 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss: 0.7301980257034302 Validation Accuracy: 0.5787999033927917\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss: 0.7178218364715576 Validation Accuracy: 0.5983998775482178\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss: 0.7487623691558838 Validation Accuracy: 0.601599931716919\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss: 0.7475247383117676 Validation Accuracy: 0.5933999419212341\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss: 0.728960394859314 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss: 0.7289604544639587 Validation Accuracy: 0.5797999501228333\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss: 0.7202970385551453 Validation Accuracy: 0.5995999574661255\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss: 0.7487624287605286 Validation Accuracy: 0.602199912071228\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss: 0.7450494766235352 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss: 0.728960394859314 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss: 0.7277228236198425 Validation Accuracy: 0.579599916934967\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss: 0.7215346693992615 Validation Accuracy: 0.6001998782157898\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss: 0.7574257850646973 Validation Accuracy: 0.6039999127388\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss: 0.7450495362281799 Validation Accuracy: 0.587199866771698\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss: 0.7363861799240112 Validation Accuracy: 0.591999888420105\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss: 0.7264851927757263 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss: 0.7165841460227966 Validation Accuracy: 0.5941999554634094\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss: 0.7561880946159363 Validation Accuracy: 0.5959998965263367\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss: 0.756188154220581 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss: 0.7215346693992615 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss: 0.7264851331710815 Validation Accuracy: 0.58079993724823\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss: 0.7240098714828491 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss: 0.7636138796806335 Validation Accuracy: 0.598599910736084\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss: 0.7462871670722961 Validation Accuracy: 0.590199887752533\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss: 0.728960394859314 Validation Accuracy: 0.5875998735427856\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss: 0.7202970385551453 Validation Accuracy: 0.5757998824119568\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss: 0.7091584205627441 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss: 0.7574257254600525 Validation Accuracy: 0.602199912071228\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss: 0.7487624287605286 Validation Accuracy: 0.5835999250411987\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss: 0.7277228236198425 Validation Accuracy: 0.586199939250946\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss: 0.7301980257034302 Validation Accuracy: 0.5809999704360962\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss: 0.699257493019104 Validation Accuracy: 0.5981999039649963\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss: 0.7524752616882324 Validation Accuracy: 0.5983999371528625\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss: 0.75 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss: 0.7252475619316101 Validation Accuracy: 0.5867999792098999\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss: 0.7227723002433777 Validation Accuracy: 0.5843998789787292\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss: 0.6943069696426392 Validation Accuracy: 0.5917999744415283\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss: 0.7413365840911865 Validation Accuracy: 0.5975998640060425\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss: 0.7611386179924011 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss: 0.7240098714828491 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss: 0.714108943939209 Validation Accuracy: 0.5801999568939209\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss: 0.6943069100379944 Validation Accuracy: 0.5971999168395996\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss: 0.7202970385551453 Validation Accuracy: 0.5917999148368835\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss: 0.7400989532470703 Validation Accuracy: 0.5847998261451721\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss: 0.7264851331710815 Validation Accuracy: 0.5897999405860901\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss: 0.6930692791938782 Validation Accuracy: 0.5701999068260193\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss: 0.7079208493232727 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss: 0.7376237511634827 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss: 0.7549505233764648 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss: 0.7301980257034302 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss: 0.7103960514068604 Validation Accuracy: 0.568199872970581\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss: 0.7017326951026917 Validation Accuracy: 0.5771999359130859\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss: 0.728960394859314 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss: 0.7301980257034302 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss: 0.7326732873916626 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss: 0.7128713130950928 Validation Accuracy: 0.5725998878479004\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss: 0.7066832184791565 Validation Accuracy: 0.5775998830795288\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss: 0.7227722406387329 Validation Accuracy: 0.5767999291419983\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss: 0.7339109182357788 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss: 0.7190594673156738 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss: 0.7227723002433777 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss: 0.7339107990264893 Validation Accuracy: 0.5917999148368835\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss: 0.7252475023269653 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss: 0.7339109182357788 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss: 0.7301979660987854 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss: 0.7376237511634827 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss: 0.7240099310874939 Validation Accuracy: 0.597399890422821\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss: 0.7178217172622681 Validation Accuracy: 0.5783998966217041\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss: 0.7425742745399475 Validation Accuracy: 0.5857998728752136\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss: 0.728960394859314 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss: 0.7363861799240112 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss: 0.6992573738098145 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss: 0.7240098714828491 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss: 0.7475247383117676 Validation Accuracy: 0.5931999683380127\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss: 0.698019802570343 Validation Accuracy: 0.5835999250411987\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss: 0.7264851927757263 Validation Accuracy: 0.5911998748779297\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss: 0.676980197429657 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss: 0.7202970385551453 Validation Accuracy: 0.5875998735427856\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss: 0.756188154220581 Validation Accuracy: 0.5961998701095581\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss: 0.7079208493232727 Validation Accuracy: 0.5843998789787292\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss: 0.7153465151786804 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss: 0.7029702663421631 Validation Accuracy: 0.5991998910903931\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss: 0.7425742149353027 Validation Accuracy: 0.5961998701095581\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss: 0.7611386775970459 Validation Accuracy: 0.5949999094009399\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss: 0.7165841460227966 Validation Accuracy: 0.5845999121665955\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss: 0.7227722406387329 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss: 0.7103959918022156 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss: 0.7289603352546692 Validation Accuracy: 0.591999888420105\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss: 0.7586634159088135 Validation Accuracy: 0.5937999486923218\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss: 0.7227723002433777 Validation Accuracy: 0.5829998850822449\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss: 0.7178218364715576 Validation Accuracy: 0.5929998159408569\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss: 0.7215346097946167 Validation Accuracy: 0.5961998701095581\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss: 0.7376238107681274 Validation Accuracy: 0.5949999094009399\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss: 0.7611386179924011 Validation Accuracy: 0.6027998924255371\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss: 0.7388613820075989 Validation Accuracy: 0.5931998491287231\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss: 0.7252475023269653 Validation Accuracy: 0.5965998768806458\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss: 0.7165841460227966 Validation Accuracy: 0.598599910736084\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss: 0.728960394859314 Validation Accuracy: 0.5893998742103577\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss: 0.7363861799240112 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss: 0.7277227640151978 Validation Accuracy: 0.5845999717712402\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss: 0.7066831588745117 Validation Accuracy: 0.5889999866485596\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss: 0.7103960514068604 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss: 0.7413366436958313 Validation Accuracy: 0.5987999439239502\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss: 0.7636138796806335 Validation Accuracy: 0.6017998456954956\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss: 0.7252475023269653 Validation Accuracy: 0.5897999405860901\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss: 0.7277228236198425 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss: 0.7103959918022156 Validation Accuracy: 0.5999999046325684\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss: 0.7487623691558838 Validation Accuracy: 0.6067999005317688\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss: 0.7685643434524536 Validation Accuracy: 0.601599931716919\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss: 0.733910858631134 Validation Accuracy: 0.5897998809814453\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss: 0.7252476215362549 Validation Accuracy: 0.5993999242782593\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss: 0.7116336226463318 Validation Accuracy: 0.6013998985290527\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss: 0.7574257254600525 Validation Accuracy: 0.6095998883247375\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss: 0.7599009871482849 Validation Accuracy: 0.6047999262809753\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss: 0.7450495362281799 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss: 0.7363861799240112 Validation Accuracy: 0.5961999297142029\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss: 0.719059407711029 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss: 0.7524752616882324 Validation Accuracy: 0.6011998653411865\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss: 0.7549504637718201 Validation Accuracy: 0.6053999066352844\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss: 0.7425742745399475 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss: 0.7301980257034302 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss: 0.7066831588745117 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss: 0.7487623691558838 Validation Accuracy: 0.6029999852180481\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss: 0.7586633563041687 Validation Accuracy: 0.6039999723434448\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss: 0.7487624287605286 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss: 0.7462871670722961 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss: 0.7240099310874939 Validation Accuracy: 0.5943998694419861\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss: 0.7487623691558838 Validation Accuracy: 0.5911998748779297\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss: 0.756188154220581 Validation Accuracy: 0.5971999168395996\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss: 0.7475247383117676 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss: 0.7524752616882324 Validation Accuracy: 0.6021999716758728\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss: 0.7264851331710815 Validation Accuracy: 0.5981998443603516\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss: 0.7475246787071228 Validation Accuracy: 0.5925998687744141\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss: 0.7561880946159363 Validation Accuracy: 0.6009998917579651\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss: 0.7549505233764648 Validation Accuracy: 0.593799889087677\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss: 0.7450494766235352 Validation Accuracy: 0.596799910068512\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss: 0.7376237511634827 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss: 0.7376238107681274 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss: 0.7648515105247498 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss: 0.7462871074676514 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss: 0.7202969789505005 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss: 0.7116336226463318 Validation Accuracy: 0.586199939250946\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss: 0.7376237511634827 Validation Accuracy: 0.5911999344825745\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss: 0.7413366436958313 Validation Accuracy: 0.5953998565673828\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss: 0.7351484894752502 Validation Accuracy: 0.5887999534606934\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss: 0.7363861203193665 Validation Accuracy: 0.5993998646736145\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss: 0.7227723002433777 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss: 0.7487623691558838 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss: 0.7537128329277039 Validation Accuracy: 0.5979999303817749\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss: 0.75 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss: 0.75 Validation Accuracy: 0.605199933052063\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss: 0.712871253490448 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss: 0.7438119053840637 Validation Accuracy: 0.5889999270439148\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss: 0.7450495362281799 Validation Accuracy: 0.5941999554634094\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss: 0.7264851927757263 Validation Accuracy: 0.5935999155044556\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss: 0.7054454684257507 Validation Accuracy: 0.5863998532295227\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss: 0.7029703259468079 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss: 0.7599009871482849 Validation Accuracy: 0.6007999181747437\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss: 0.7636138796806335 Validation Accuracy: 0.6017999053001404\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss: 0.7425742745399475 Validation Accuracy: 0.5951999425888062\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss: 0.7227722406387329 Validation Accuracy: 0.5961999297142029\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss: 0.7153465747833252 Validation Accuracy: 0.595599889755249\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss: 0.7599009275436401 Validation Accuracy: 0.5993999242782593\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss: 0.7599009871482849 Validation Accuracy: 0.6049998998641968\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss: 0.7425742745399475 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss: 0.7277227640151978 Validation Accuracy: 0.5965999960899353\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss: 0.7178217768669128 Validation Accuracy: 0.5971999168395996\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss: 0.7586634159088135 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss: 0.7698019742965698 Validation Accuracy: 0.6093999147415161\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss: 0.7388613224029541 Validation Accuracy: 0.59579998254776\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss: 0.7339109182357788 Validation Accuracy: 0.5945999026298523\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss: 0.7202970385551453 Validation Accuracy: 0.5973998308181763\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss: 0.7611386775970459 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss: 0.7784653902053833 Validation Accuracy: 0.605199933052063\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss: 0.7500000596046448 Validation Accuracy: 0.602199912071228\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss: 0.7326732873916626 Validation Accuracy: 0.5979999303817749\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss: 0.712871253490448 Validation Accuracy: 0.5937999486923218\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss: 0.7388613820075989 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss: 0.7660890817642212 Validation Accuracy: 0.5923999547958374\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss: 0.728960394859314 Validation Accuracy: 0.5939999222755432\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss: 0.7202970385551453 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss: 0.7153465151786804 Validation Accuracy: 0.5917999744415283\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss: 0.7623762488365173 Validation Accuracy: 0.5927998423576355\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss: 0.7747524380683899 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss: 0.7537128925323486 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss: 0.7314356565475464 Validation Accuracy: 0.5949999690055847\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss: 0.7116336822509766 Validation Accuracy: 0.5953999161720276\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss: 0.7698019742965698 Validation Accuracy: 0.5989998579025269\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss: 0.7759901285171509 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss: 0.757425844669342 Validation Accuracy: 0.5979999303817749\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss: 0.7314356565475464 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss: 0.7240098714828491 Validation Accuracy: 0.5981999039649963\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss: 0.7648515105247498 Validation Accuracy: 0.5991998910903931\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss: 0.7809405326843262 Validation Accuracy: 0.6017998456954956\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss: 0.7673267722129822 Validation Accuracy: 0.6013999581336975\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss: 0.7425742745399475 Validation Accuracy: 0.5971999764442444\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss: 0.728960394859314 Validation Accuracy: 0.6009998917579651\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss: 0.7623762488365173 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss: 0.780940592288971 Validation Accuracy: 0.5953998565673828\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss: 0.7611386179924011 Validation Accuracy: 0.6027998924255371\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss: 0.7561880946159363 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss: 0.7339109182357788 Validation Accuracy: 0.6065999269485474\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss: 0.766089141368866 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss: 0.7772277593612671 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss: 0.772277295589447 Validation Accuracy: 0.6017999053001404\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss: 0.7499999403953552 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss: 0.7450495362281799 Validation Accuracy: 0.6027998924255371\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss: 0.7599010467529297 Validation Accuracy: 0.577799916267395\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss: 0.7636138200759888 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss: 0.7574257850646973 Validation Accuracy: 0.596799910068512\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss: 0.75 Validation Accuracy: 0.5959999561309814\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss: 0.7339107990264893 Validation Accuracy: 0.5967998504638672\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss: 0.7611386775970459 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss: 0.7586632966995239 Validation Accuracy: 0.5903998613357544\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss: 0.7487623691558838 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss: 0.7215346693992615 Validation Accuracy: 0.5775998830795288\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss: 0.7240099310874939 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss: 0.7450495362281799 Validation Accuracy: 0.5793998837471008\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss: 0.7537128329277039 Validation Accuracy: 0.5879998803138733\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss: 0.7549504637718201 Validation Accuracy: 0.5959998965263367\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss: 0.7462871670722961 Validation Accuracy: 0.5867999792098999\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss: 0.7165842056274414 Validation Accuracy: 0.5943998694419861\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss: 0.7549505233764648 Validation Accuracy: 0.5943998694419861\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss: 0.7512376308441162 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss: 0.7376237511634827 Validation Accuracy: 0.5975998640060425\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss: 0.75 Validation Accuracy: 0.5889999270439148\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss: 0.7153464555740356 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss: 0.7561880946159363 Validation Accuracy: 0.5765998959541321\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss: 0.7574257850646973 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss: 0.7487623691558838 Validation Accuracy: 0.5965998768806458\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss: 0.7673267722129822 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss: 0.7165840864181519 Validation Accuracy: 0.5925999879837036\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss: 0.7673267126083374 Validation Accuracy: 0.5869999527931213\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss: 0.766089141368866 Validation Accuracy: 0.6009998917579651\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss: 0.75 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss: 0.7549505233764648 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss: 0.7289604544639587 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss: 0.7784653306007385 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss: 0.7698019742965698 Validation Accuracy: 0.5981999039649963\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss: 0.7512376308441162 Validation Accuracy: 0.5997998714447021\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss: 0.771039605140686 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss: 0.735148549079895 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss: 0.7735148668289185 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss: 0.7574257254600525 Validation Accuracy: 0.6003998517990112\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss: 0.7475247979164124 Validation Accuracy: 0.5965998768806458\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss: 0.7623763084411621 Validation Accuracy: 0.5963999629020691\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss: 0.743811845779419 Validation Accuracy: 0.5975998640060425\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss: 0.7759900689125061 Validation Accuracy: 0.5905999541282654\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss: 0.7846534848213196 Validation Accuracy: 0.598599910736084\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss: 0.7462871074676514 Validation Accuracy: 0.5983999371528625\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss: 0.7660892009735107 Validation Accuracy: 0.5971999168395996\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss: 0.7462871074676514 Validation Accuracy: 0.5949999690055847\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss: 0.7821782231330872 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss: 0.7759900689125061 Validation Accuracy: 0.6005998849868774\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss: 0.7549505233764648 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss: 0.7722772359848022 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss: 0.7400990128517151 Validation Accuracy: 0.5939999222755432\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss: 0.769801914691925 Validation Accuracy: 0.5848000049591064\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss: 0.7710395455360413 Validation Accuracy: 0.597399890422821\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss: 0.7537128925323486 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss: 0.7772277593612671 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss: 0.75 Validation Accuracy: 0.6011998653411865\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss: 0.7698020339012146 Validation Accuracy: 0.5833999514579773\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss: 0.7698020339012146 Validation Accuracy: 0.6021999716758728\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss: 0.7462871074676514 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss: 0.7722772359848022 Validation Accuracy: 0.5991999506950378\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss: 0.7537128329277039 Validation Accuracy: 0.6005998849868774\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss: 0.7735148072242737 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss: 0.7722771763801575 Validation Accuracy: 0.5927999019622803\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss: 0.7623761892318726 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss: 0.7821782231330872 Validation Accuracy: 0.5991998910903931\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss: 0.7537128925323486 Validation Accuracy: 0.6045998930931091\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss: 0.7735148668289185 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss: 0.7834158539772034 Validation Accuracy: 0.602199912071228\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss: 0.7747525572776794 Validation Accuracy: 0.5963999629020691\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss: 0.771039605140686 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss: 0.7574257254600525 Validation Accuracy: 0.5995999574661255\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss: 0.7722772359848022 Validation Accuracy: 0.5831999778747559\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss: 0.7797030210494995 Validation Accuracy: 0.5981999039649963\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss: 0.766089141368866 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss: 0.7883663773536682 Validation Accuracy: 0.6011999249458313\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss: 0.7574257254600525 Validation Accuracy: 0.6041999459266663\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss: 0.7797030210494995 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss: 0.7846534848213196 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss: 0.7698020339012146 Validation Accuracy: 0.5983998775482178\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss: 0.7759900689125061 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss: 0.7549505233764648 Validation Accuracy: 0.6053999066352844\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss: 0.7735148668289185 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss: 0.780940592288971 Validation Accuracy: 0.5959999561309814\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss: 0.7759901285171509 Validation Accuracy: 0.5992000102996826\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss: 0.7698019742965698 Validation Accuracy: 0.5957998633384705\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss: 0.7549505233764648 Validation Accuracy: 0.6003998517990112\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss: 0.7784653306007385 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss: 0.7908415794372559 Validation Accuracy: 0.5999999046325684\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss: 0.7722772359848022 Validation Accuracy: 0.5991998910903931\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss: 0.785891056060791 Validation Accuracy: 0.5995998978614807\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss: 0.7636138796806335 Validation Accuracy: 0.5999999046325684\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss: 0.7821782827377319 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss: 0.785891056060791 Validation Accuracy: 0.6017999053001404\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss: 0.7772277593612671 Validation Accuracy: 0.5971999168395996\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss: 0.7809405326843262 Validation Accuracy: 0.5981999039649963\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss: 0.7586634159088135 Validation Accuracy: 0.592799961566925\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss: 0.7759900689125061 Validation Accuracy: 0.5895999073982239\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss: 0.7908415794372559 Validation Accuracy: 0.6001999378204346\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss: 0.7735148668289185 Validation Accuracy: 0.5989999771118164\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss: 0.7821782231330872 Validation Accuracy: 0.602199912071228\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss: 0.7586634159088135 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss: 0.7834158539772034 Validation Accuracy: 0.5929999351501465\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss: 0.7883663177490234 Validation Accuracy: 0.6001999378204346\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss: 0.7797029614448547 Validation Accuracy: 0.5973999500274658\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss: 0.7759901285171509 Validation Accuracy: 0.6035999059677124\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss: 0.7499999403953552 Validation Accuracy: 0.6039999723434448\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss: 0.7834157943725586 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss: 0.7846534848213196 Validation Accuracy: 0.6059999465942383\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss: 0.7834158539772034 Validation Accuracy: 0.597399890422821\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss: 0.7821782231330872 Validation Accuracy: 0.5979999303817749\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss: 0.7549504637718201 Validation Accuracy: 0.5993999242782593\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss: 0.7908415794372559 Validation Accuracy: 0.5959998965263367\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss: 0.7957921028137207 Validation Accuracy: 0.6027999520301819\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss: 0.7797030210494995 Validation Accuracy: 0.5951999425888062\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss: 0.7883663177490234 Validation Accuracy: 0.5969999432563782\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss: 0.7561880946159363 Validation Accuracy: 0.5961999297142029\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss: 0.787128746509552 Validation Accuracy: 0.5869999527931213\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss: 0.8007425665855408 Validation Accuracy: 0.6003999710083008\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss: 0.7772277593612671 Validation Accuracy: 0.5951999425888062\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss: 0.7834158539772034 Validation Accuracy: 0.5977998375892639\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss: 0.7524752616882324 Validation Accuracy: 0.5955999493598938\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss: 0.7933168411254883 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss: 0.7759900689125061 Validation Accuracy: 0.5887999534606934\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss: 0.7660890817642212 Validation Accuracy: 0.5951998829841614\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss: 0.7636138200759888 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss: 0.7376237511634827 Validation Accuracy: 0.5959999561309814\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss: 0.7933168411254883 Validation Accuracy: 0.5929999351501465\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss: 0.780940592288971 Validation Accuracy: 0.598599910736084\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss: 0.7759901285171509 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss: 0.7759900689125061 Validation Accuracy: 0.5993998646736145\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss: 0.7537128329277039 Validation Accuracy: 0.5967999696731567\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss: 0.7834157943725586 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss: 0.7772276401519775 Validation Accuracy: 0.5897999405860901\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss: 0.7772277593612671 Validation Accuracy: 0.6001999378204346\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss: 0.7599009871482849 Validation Accuracy: 0.5969999432563782\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss: 0.7450494766235352 Validation Accuracy: 0.5997998714447021\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss: 0.7883663177490234 Validation Accuracy: 0.5935999155044556\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss: 0.7883663177490234 Validation Accuracy: 0.5959998965263367\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss: 0.7623762488365173 Validation Accuracy: 0.5949999094009399\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss: 0.7735148668289185 Validation Accuracy: 0.600399911403656\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss: 0.7425742149353027 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss: 0.7970296740531921 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss: 0.7933167815208435 Validation Accuracy: 0.5981998443603516\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss: 0.7945544719696045 Validation Accuracy: 0.601599931716919\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss: 0.7759901285171509 Validation Accuracy: 0.6019999384880066\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss: 0.7636138796806335 Validation Accuracy: 0.5941999554634094\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss: 0.785891056060791 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss: 0.8032177686691284 Validation Accuracy: 0.5945998430252075\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss: 0.785891056060791 Validation Accuracy: 0.6031998991966248\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss: 0.7759900689125061 Validation Accuracy: 0.6015998721122742\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss: 0.7599009871482849 Validation Accuracy: 0.5963999629020691\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss: 0.7945544719696045 Validation Accuracy: 0.5911999940872192\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss: 0.7982673048973083 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss: 0.7896039485931396 Validation Accuracy: 0.6035998463630676\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss: 0.7834158539772034 Validation Accuracy: 0.6015998721122742\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss: 0.7462871074676514 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss: 0.8019802570343018 Validation Accuracy: 0.5979998707771301\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss: 0.801980197429657 Validation Accuracy: 0.5955999493598938\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss: 0.7858911156654358 Validation Accuracy: 0.6015998721122742\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss: 0.7772276997566223 Validation Accuracy: 0.5983998775482178\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss: 0.7549504637718201 Validation Accuracy: 0.5989999771118164\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss: 0.8032178282737732 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss: 0.8032178282737732 Validation Accuracy: 0.5953999161720276\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss: 0.7896039485931396 Validation Accuracy: 0.5981999635696411\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss: 0.7784653306007385 Validation Accuracy: 0.6037999391555786\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss: 0.7599010467529297 Validation Accuracy: 0.5961999297142029\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss: 0.7920792102813721 Validation Accuracy: 0.5959999561309814\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss: 0.8032178282737732 Validation Accuracy: 0.6041999459266663\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss: 0.7957920432090759 Validation Accuracy: 0.5979999303817749\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss: 0.7821782231330872 Validation Accuracy: 0.6005998849868774\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss: 0.7698019742965698 Validation Accuracy: 0.598599910736084\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss: 0.8044554591178894 Validation Accuracy: 0.5983999371528625\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss: 0.7933167815208435 Validation Accuracy: 0.6013998985290527\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss: 0.7957920432090759 Validation Accuracy: 0.6027998924255371\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss: 0.7821782231330872 Validation Accuracy: 0.5983999371528625\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss: 0.7586634159088135 Validation Accuracy: 0.596799910068512\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss: 0.808168351650238 Validation Accuracy: 0.6009998917579651\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss: 0.7933168411254883 Validation Accuracy: 0.6007999181747437\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss: 0.7883663177490234 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss: 0.7883663177490234 Validation Accuracy: 0.597399890422821\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss: 0.7636139392852783 Validation Accuracy: 0.596799910068512\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss: 0.8007425665855408 Validation Accuracy: 0.5971999168395996\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss: 0.800742506980896 Validation Accuracy: 0.6025999188423157\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss: 0.7933167815208435 Validation Accuracy: 0.5979999303817749\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss: 0.7896039485931396 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss: 0.766089141368866 Validation Accuracy: 0.6007999181747437\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss: 0.7945544123649597 Validation Accuracy: 0.5977999567985535\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss: 0.7957920432090759 Validation Accuracy: 0.5991999506950378\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss: 0.7920792102813721 Validation Accuracy: 0.6029999256134033\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss: 0.7809406518936157 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss: 0.7784653306007385 Validation Accuracy: 0.6013998985290527\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss: 0.8044554591178894 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss: 0.7834157943725586 Validation Accuracy: 0.5893998742103577\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss: 0.7970296740531921 Validation Accuracy: 0.6047998666763306\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss: 0.7759901285171509 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss: 0.7759901285171509 Validation Accuracy: 0.6005999445915222\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss: 0.801980197429657 Validation Accuracy: 0.5937999486923218\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss: 0.7759900689125061 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss: 0.785891056060791 Validation Accuracy: 0.5983998775482178\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss: 0.7883663177490234 Validation Accuracy: 0.5945999026298523\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss: 0.7772276997566223 Validation Accuracy: 0.6019998788833618\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss: 0.7883663773536682 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss: 0.7896039485931396 Validation Accuracy: 0.5911999344825745\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss: 0.780940592288971 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss: 0.7636138796806335 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss: 0.7673267722129822 Validation Accuracy: 0.5959999561309814\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss: 0.7957921028137207 Validation Accuracy: 0.5927999019622803\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss: 0.7920792102813721 Validation Accuracy: 0.5887999534606934\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss: 0.764851450920105 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss: 0.7673267126083374 Validation Accuracy: 0.5893998742103577\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss: 0.7747524976730347 Validation Accuracy: 0.5953999757766724\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss: 0.7908415794372559 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss: 0.7883663773536682 Validation Accuracy: 0.5955999493598938\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss: 0.7599009871482849 Validation Accuracy: 0.5895999073982239\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss: 0.764851450920105 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss: 0.7599009275436401 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss: 0.7883663177490234 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss: 0.7846534252166748 Validation Accuracy: 0.5927999019622803\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss: 0.7846534252166748 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss: 0.7660890817642212 Validation Accuracy: 0.5911999344825745\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss: 0.7623762488365173 Validation Accuracy: 0.5903999209403992\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss: 0.7846534252166748 Validation Accuracy: 0.5945999026298523\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss: 0.7784653306007385 Validation Accuracy: 0.5903999209403992\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss: 0.7759901285171509 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss: 0.7611386179924011 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss: 0.7549505233764648 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss: 0.7797030210494995 Validation Accuracy: 0.5897998809814453\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss: 0.7995049357414246 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss: 0.7698020339012146 Validation Accuracy: 0.5877999663352966\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss: 0.7685643434524536 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss: 0.7648515105247498 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss: 0.7883663177490234 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss: 0.7957921028137207 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss: 0.7698019742965698 Validation Accuracy: 0.5959998369216919\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss: 0.7834157943725586 Validation Accuracy: 0.5919999480247498\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss: 0.7747524976730347 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss: 0.780940592288971 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss: 0.7920792102813721 Validation Accuracy: 0.596799910068512\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss: 0.7797030210494995 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss: 0.7772277593612671 Validation Accuracy: 0.5939999222755432\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss: 0.7797030210494995 Validation Accuracy: 0.5995998978614807\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss: 0.7970297336578369 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss: 0.800742506980896 Validation Accuracy: 0.5927999019622803\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss: 0.7821781635284424 Validation Accuracy: 0.6029999256134033\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss: 0.7747524380683899 Validation Accuracy: 0.5933999419212341\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss: 0.7747524976730347 Validation Accuracy: 0.5987998843193054\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss: 0.7759901285171509 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss: 0.7896040081977844 Validation Accuracy: 0.5911999344825745\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss: 0.7722772359848022 Validation Accuracy: 0.5981999635696411\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss: 0.7747524976730347 Validation Accuracy: 0.5897999405860901\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss: 0.7772276401519775 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss: 0.771039605140686 Validation Accuracy: 0.5895999073982239\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss: 0.7995049357414246 Validation Accuracy: 0.5959998965263367\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss: 0.7772276997566223 Validation Accuracy: 0.6057999134063721\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss: 0.771039605140686 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss: 0.7759901285171509 Validation Accuracy: 0.598599910736084\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss: 0.771039605140686 Validation Accuracy: 0.5847998857498169\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss: 0.7883663177490234 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss: 0.7797030210494995 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss: 0.7735148668289185 Validation Accuracy: 0.5881999731063843\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss: 0.7846534252166748 Validation Accuracy: 0.5971999168395996\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss: 0.7722772359848022 Validation Accuracy: 0.5809999108314514\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss: 0.7834158539772034 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss: 0.771039605140686 Validation Accuracy: 0.5917998552322388\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss: 0.7450495362281799 Validation Accuracy: 0.5821998715400696\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss: 0.7821782231330872 Validation Accuracy: 0.5893998742103577\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss: 0.780940592288971 Validation Accuracy: 0.5897998809814453\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss: 0.7784653902053833 Validation Accuracy: 0.6029999256134033\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss: 0.7759900689125061 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss: 0.7623762488365173 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss: 0.7797029614448547 Validation Accuracy: 0.5929999351501465\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss: 0.7698020339012146 Validation Accuracy: 0.5847998857498169\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss: 0.7945544719696045 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss: 0.7759900689125061 Validation Accuracy: 0.5903999209403992\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss: 0.766089141368866 Validation Accuracy: 0.5859999060630798\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss: 0.7636138796806335 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss: 0.7883663177490234 Validation Accuracy: 0.5927999019622803\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss: 0.787128746509552 Validation Accuracy: 0.6011999249458313\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss: 0.7797030210494995 Validation Accuracy: 0.5935999155044556\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss: 0.7747524380683899 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss: 0.7425742149353027 Validation Accuracy: 0.58079993724823\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss: 0.7908415794372559 Validation Accuracy: 0.5897998809814453\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss: 0.7957921028137207 Validation Accuracy: 0.5981999039649963\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss: 0.7883663177490234 Validation Accuracy: 0.601599931716919\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss: 0.780940592288971 Validation Accuracy: 0.5903999209403992\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss: 0.7462871670722961 Validation Accuracy: 0.5825998783111572\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss: 0.780940592288971 Validation Accuracy: 0.5915998816490173\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss: 0.7945544719696045 Validation Accuracy: 0.6031999588012695\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss: 0.7933168411254883 Validation Accuracy: 0.5981999039649963\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss: 0.7797029614448547 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss: 0.7648515105247498 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss: 0.7834157943725586 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss: 0.7908415794372559 Validation Accuracy: 0.601599931716919\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss: 0.7846534252166748 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss: 0.7747524976730347 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss: 0.7611385583877563 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss: 0.7945544719696045 Validation Accuracy: 0.5911999344825745\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss: 0.7995048761367798 Validation Accuracy: 0.6039998531341553\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss: 0.7871286869049072 Validation Accuracy: 0.5971999168395996\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss: 0.7735148668289185 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss: 0.7648515105247498 Validation Accuracy: 0.585399866104126\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss: 0.7908415794372559 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss: 0.7970296740531921 Validation Accuracy: 0.6029999256134033\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss: 0.7933167815208435 Validation Accuracy: 0.6001999378204346\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss: 0.787128746509552 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss: 0.7685643434524536 Validation Accuracy: 0.5875998735427856\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss: 0.7995049357414246 Validation Accuracy: 0.5959998965263367\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss: 0.7995049953460693 Validation Accuracy: 0.6027998924255371\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss: 0.7920792102813721 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss: 0.7797029614448547 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss: 0.7574257850646973 Validation Accuracy: 0.5815998911857605\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss: 0.8044554591178894 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss: 0.8044553995132446 Validation Accuracy: 0.6005998849868774\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss: 0.7846534848213196 Validation Accuracy: 0.5987999439239502\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss: 0.7982673048973083 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss: 0.7871286869049072 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss: 0.8056930303573608 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss: 0.8056930899620056 Validation Accuracy: 0.597399890422821\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss: 0.7834158539772034 Validation Accuracy: 0.598599910736084\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss: 0.77970290184021 Validation Accuracy: 0.584399938583374\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss: 0.7673267126083374 Validation Accuracy: 0.5845999121665955\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss: 0.7995049357414246 Validation Accuracy: 0.584399938583374\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss: 0.806930661201477 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss: 0.7784653902053833 Validation Accuracy: 0.6013999581336975\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss: 0.7883663177490234 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss: 0.7735148668289185 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss: 0.8032177686691284 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss: 0.8081682920455933 Validation Accuracy: 0.596799910068512\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss: 0.7908415794372559 Validation Accuracy: 0.6025999188423157\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss: 0.7957921028137207 Validation Accuracy: 0.5925999879837036\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss: 0.7747524976730347 Validation Accuracy: 0.5855998992919922\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss: 0.7896039485931396 Validation Accuracy: 0.5747998952865601\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss: 0.7896039485931396 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss: 0.785891056060791 Validation Accuracy: 0.6007999181747437\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss: 0.785891056060791 Validation Accuracy: 0.5915998816490173\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss: 0.7735148668289185 Validation Accuracy: 0.5823999643325806\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss: 0.7685644030570984 Validation Accuracy: 0.5743998885154724\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss: 0.7759901285171509 Validation Accuracy: 0.5779999494552612\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss: 0.7858911156654358 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss: 0.7933167219161987 Validation Accuracy: 0.5977998971939087\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss: 0.7784653902053833 Validation Accuracy: 0.5859999060630798\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss: 0.7920792102813721 Validation Accuracy: 0.5707998871803284\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss: 0.7759901285171509 Validation Accuracy: 0.5812000036239624\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss: 0.7834159135818481 Validation Accuracy: 0.5941999554634094\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss: 0.787128746509552 Validation Accuracy: 0.596799910068512\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss: 0.7685643434524536 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss: 0.7772276997566223 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss: 0.7982672452926636 Validation Accuracy: 0.5849999189376831\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss: 0.7871286869049072 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss: 0.7871286869049072 Validation Accuracy: 0.5845998525619507\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss: 0.7809406518936157 Validation Accuracy: 0.5843998789787292\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss: 0.7648515105247498 Validation Accuracy: 0.5639998912811279\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss: 0.7908416390419006 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss: 0.7759901285171509 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss: 0.7735149264335632 Validation Accuracy: 0.5833998918533325\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss: 0.771039605140686 Validation Accuracy: 0.5803999900817871\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss: 0.7871286869049072 Validation Accuracy: 0.5783999562263489\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss: 0.780940592288971 Validation Accuracy: 0.5987999439239502\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss: 0.7462871074676514 Validation Accuracy: 0.584399938583374\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss: 0.7648515105247498 Validation Accuracy: 0.58079993724823\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss: 0.771039605140686 Validation Accuracy: 0.5791999697685242\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss: 0.7883663177490234 Validation Accuracy: 0.5911999344825745\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss: 0.7871286869049072 Validation Accuracy: 0.597399890422821\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss: 0.771039605140686 Validation Accuracy: 0.584399938583374\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss: 0.7623761892318726 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss: 0.7660890817642212 Validation Accuracy: 0.5795999765396118\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss: 0.7698020339012146 Validation Accuracy: 0.5903999209403992\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss: 0.787128746509552 Validation Accuracy: 0.6035999059677124\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss: 0.7747525572776794 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss: 0.7809405326843262 Validation Accuracy: 0.577799916267395\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss: 0.7809406518936157 Validation Accuracy: 0.5839998722076416\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss: 0.7759901285171509 Validation Accuracy: 0.5833998918533325\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss: 0.7896039485931396 Validation Accuracy: 0.6011998653411865\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss: 0.7698019742965698 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss: 0.7846534848213196 Validation Accuracy: 0.5811998844146729\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss: 0.7549505233764648 Validation Accuracy: 0.5781999230384827\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss: 0.7883663177490234 Validation Accuracy: 0.5857998728752136\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss: 0.7636138796806335 Validation Accuracy: 0.589199960231781\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss: 0.771039605140686 Validation Accuracy: 0.587199866771698\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss: 0.771039605140686 Validation Accuracy: 0.5787999033927917\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss: 0.7450495362281799 Validation Accuracy: 0.5747999548912048\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss: 0.7685643434524536 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss: 0.7710395455360413 Validation Accuracy: 0.5895999670028687\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss: 0.7908415198326111 Validation Accuracy: 0.5999999046325684\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss: 0.7450494766235352 Validation Accuracy: 0.5769999027252197\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss: 0.7772276997566223 Validation Accuracy: 0.5895999073982239\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss: 0.7784653306007385 Validation Accuracy: 0.5931999683380127\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss: 0.771039605140686 Validation Accuracy: 0.5961999893188477\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss: 0.8106435537338257 Validation Accuracy: 0.6025998592376709\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss: 0.7623763084411621 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss: 0.7920792102813721 Validation Accuracy: 0.5855998992919922\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss: 0.7759901285171509 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss: 0.7759901285171509 Validation Accuracy: 0.5989999771118164\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss: 0.8019801378250122 Validation Accuracy: 0.6011998653411865\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss: 0.7698019742965698 Validation Accuracy: 0.5853999257087708\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss: 0.7846534252166748 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss: 0.7846534848213196 Validation Accuracy: 0.5855998992919922\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss: 0.7846534252166748 Validation Accuracy: 0.596799910068512\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss: 0.8007425665855408 Validation Accuracy: 0.5953998565673828\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss: 0.743811845779419 Validation Accuracy: 0.5779999494552612\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss: 0.7995049953460693 Validation Accuracy: 0.585599958896637\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss: 0.7883663177490234 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss: 0.7933168411254883 Validation Accuracy: 0.5967998504638672\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss: 0.8094059824943542 Validation Accuracy: 0.6037999391555786\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss: 0.7685643434524536 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss: 0.785891056060791 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss: 0.7920792102813721 Validation Accuracy: 0.587399959564209\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss: 0.7896039485931396 Validation Accuracy: 0.598599910736084\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss: 0.7995048761367798 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss: 0.7611386775970459 Validation Accuracy: 0.5809999108314514\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss: 0.7982673645019531 Validation Accuracy: 0.5899999737739563\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss: 0.7834157943725586 Validation Accuracy: 0.5839999318122864\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss: 0.780940592288971 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss: 0.8044553995132446 Validation Accuracy: 0.5959998965263367\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss: 0.7611386775970459 Validation Accuracy: 0.5789998769760132\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss: 0.7945544123649597 Validation Accuracy: 0.586199939250946\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss: 0.7846534252166748 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss: 0.7896040081977844 Validation Accuracy: 0.5961999297142029\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss: 0.8193069696426392 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss: 0.75 Validation Accuracy: 0.5737999677658081\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss: 0.7846534848213196 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss: 0.7747524976730347 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss: 0.7821782827377319 Validation Accuracy: 0.5975998640060425\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss: 0.7920791506767273 Validation Accuracy: 0.597399890422821\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss: 0.7722771763801575 Validation Accuracy: 0.578999936580658\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss: 0.7623762488365173 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss: 0.771039605140686 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss: 0.8081682920455933 Validation Accuracy: 0.6033998727798462\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss: 0.8217821717262268 Validation Accuracy: 0.597399890422821\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss: 0.7945544719696045 Validation Accuracy: 0.5835999250411987\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss: 0.7871288061141968 Validation Accuracy: 0.5877999663352966\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss: 0.7784653902053833 Validation Accuracy: 0.5885999798774719\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss: 0.7908415794372559 Validation Accuracy: 0.6001998782157898\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss: 0.8094059228897095 Validation Accuracy: 0.6011999845504761\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss: 0.8032178282737732 Validation Accuracy: 0.5853999257087708\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss: 0.7933168411254883 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss: 0.7982673048973083 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss: 0.7920792102813721 Validation Accuracy: 0.5973999500274658\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss: 0.8230197429656982 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss: 0.803217887878418 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss: 0.7982673645019531 Validation Accuracy: 0.5837999582290649\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss: 0.7982673645019531 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss: 0.7995049953460693 Validation Accuracy: 0.6001998782157898\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss: 0.8118811845779419 Validation Accuracy: 0.6011999845504761\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss: 0.8044553995132446 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss: 0.8019801378250122 Validation Accuracy: 0.5929998755455017\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss: 0.8094059228897095 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss: 0.8205446004867554 Validation Accuracy: 0.602199912071228\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss: 0.818069338798523 Validation Accuracy: 0.5959999561309814\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss: 0.7970296740531921 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss: 0.8056930303573608 Validation Accuracy: 0.5877999067306519\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss: 0.8081682920455933 Validation Accuracy: 0.596799910068512\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss: 0.8193069100379944 Validation Accuracy: 0.6017999053001404\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss: 0.8094059228897095 Validation Accuracy: 0.6013998985290527\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss: 0.8044553995132446 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss: 0.7933168411254883 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss: 0.8118811845779419 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss: 0.8304455280303955 Validation Accuracy: 0.6007998585700989\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss: 0.8094059228897095 Validation Accuracy: 0.6005998849868774\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss: 0.8032177686691284 Validation Accuracy: 0.5939998626708984\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss: 0.8044554591178894 Validation Accuracy: 0.5839998722076416\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss: 0.800742506980896 Validation Accuracy: 0.593799889087677\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss: 0.8279702663421631 Validation Accuracy: 0.5961999297142029\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss: 0.8217821717262268 Validation Accuracy: 0.5999999046325684\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss: 0.8044553995132446 Validation Accuracy: 0.5895999670028687\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss: 0.7945544719696045 Validation Accuracy: 0.5859999060630798\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss: 0.8193069696426392 Validation Accuracy: 0.593799889087677\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss: 0.8205445408821106 Validation Accuracy: 0.5993999242782593\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss: 0.8205445408821106 Validation Accuracy: 0.602199912071228\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss: 0.8032177686691284 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss: 0.7871286869049072 Validation Accuracy: 0.5819998979568481\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss: 0.8131188154220581 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss: 0.823019802570343 Validation Accuracy: 0.5937999486923218\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss: 0.8304455280303955 Validation Accuracy: 0.5987998843193054\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss: 0.8056930303573608 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss: 0.8143564462661743 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss: 0.8056930303573608 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss: 0.8242573738098145 Validation Accuracy: 0.5923999547958374\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss: 0.8094059824943542 Validation Accuracy: 0.5997999310493469\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss: 0.8044553995132446 Validation Accuracy: 0.5895998477935791\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss: 0.801980197429657 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss: 0.8131188750267029 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss: 0.8254950046539307 Validation Accuracy: 0.5979998707771301\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss: 0.8217821717262268 Validation Accuracy: 0.6019999384880066\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss: 0.8007426261901855 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss: 0.7933168411254883 Validation Accuracy: 0.5785999298095703\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss: 0.8094059228897095 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss: 0.8279702663421631 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss: 0.8180692791938782 Validation Accuracy: 0.6015998721122742\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss: 0.8143564462661743 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss: 0.7945544719696045 Validation Accuracy: 0.5829998850822449\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss: 0.821782112121582 Validation Accuracy: 0.5859999656677246\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss: 0.8353960514068604 Validation Accuracy: 0.6019998788833618\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss: 0.816831648349762 Validation Accuracy: 0.601599931716919\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss: 0.8242574334144592 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss: 0.7747524976730347 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss: 0.8143564462661743 Validation Accuracy: 0.5889999866485596\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss: 0.8353960514068604 Validation Accuracy: 0.6009998917579651\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss: 0.8168317079544067 Validation Accuracy: 0.6031998991966248\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss: 0.8267326951026917 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss: 0.7908415794372559 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss: 0.8205446004867554 Validation Accuracy: 0.5845999121665955\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss: 0.8329207897186279 Validation Accuracy: 0.5983999371528625\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss: 0.8230197429656982 Validation Accuracy: 0.602199912071228\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss: 0.8081682920455933 Validation Accuracy: 0.5945999026298523\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss: 0.8081682324409485 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss: 0.7995049953460693 Validation Accuracy: 0.5833998918533325\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss: 0.8292078971862793 Validation Accuracy: 0.5941999554634094\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss: 0.8329207897186279 Validation Accuracy: 0.6027998924255371\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss: 0.8143564462661743 Validation Accuracy: 0.596799910068512\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss: 0.7809406518936157 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss: 0.8081682920455933 Validation Accuracy: 0.5845999717712402\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss: 0.8403465151786804 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss: 0.8217821717262268 Validation Accuracy: 0.6009999513626099\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss: 0.818069338798523 Validation Accuracy: 0.5937999486923218\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss: 0.8131188154220581 Validation Accuracy: 0.58899986743927\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss: 0.806930661201477 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss: 0.839108943939209 Validation Accuracy: 0.5963999032974243\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss: 0.8292080163955688 Validation Accuracy: 0.5977999567985535\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss: 0.818069338798523 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss: 0.7821782827377319 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss: 0.8193069100379944 Validation Accuracy: 0.5833998918533325\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss: 0.8230197429656982 Validation Accuracy: 0.6001998782157898\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss: 0.8254950046539307 Validation Accuracy: 0.6029999256134033\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss: 0.8118811249732971 Validation Accuracy: 0.5927999019622803\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss: 0.8118812441825867 Validation Accuracy: 0.5829998850822449\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss: 0.8094059228897095 Validation Accuracy: 0.5811998844146729\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss: 0.818069338798523 Validation Accuracy: 0.5975999236106873\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss: 0.8378713130950928 Validation Accuracy: 0.5997999310493469\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss: 0.818069338798523 Validation Accuracy: 0.5985999703407288\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss: 0.7759901285171509 Validation Accuracy: 0.5841999053955078\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss: 0.8056930899620056 Validation Accuracy: 0.5825998783111572\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss: 0.8254950642585754 Validation Accuracy: 0.5961998701095581\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss: 0.839108943939209 Validation Accuracy: 0.601599931716919\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss: 0.8193069100379944 Validation Accuracy: 0.595599889755249\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss: 0.8044554591178894 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss: 0.8081682920455933 Validation Accuracy: 0.5805999040603638\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss: 0.8279702663421631 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss: 0.818069338798523 Validation Accuracy: 0.5965999364852905\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss: 0.8131187558174133 Validation Accuracy: 0.5987998843193054\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss: 0.8131188154220581 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss: 0.7908415794372559 Validation Accuracy: 0.5833998918533325\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss: 0.7970296740531921 Validation Accuracy: 0.590999960899353\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss: 0.8094059228897095 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss: 0.8056930303573608 Validation Accuracy: 0.5951998829841614\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss: 0.8056930899620056 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss: 0.8019801378250122 Validation Accuracy: 0.5841999650001526\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss: 0.7982672452926636 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss: 0.7896040081977844 Validation Accuracy: 0.5835999250411987\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss: 0.8094059228897095 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss: 0.7982673048973083 Validation Accuracy: 0.586199939250946\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss: 0.806930661201477 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss: 0.803217887878418 Validation Accuracy: 0.5897998809814453\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss: 0.8106435537338257 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss: 0.8044554591178894 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss: 0.7933168411254883 Validation Accuracy: 0.5843998789787292\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss: 0.8242574334144592 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss: 0.8205444812774658 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss: 0.7834157943725586 Validation Accuracy: 0.586199939250946\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss: 0.7735148668289185 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss: 0.7883663177490234 Validation Accuracy: 0.5801999568939209\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss: 0.7995049953460693 Validation Accuracy: 0.5767998695373535\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss: 0.8131188154220581 Validation Accuracy: 0.58899986743927\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss: 0.7982673048973083 Validation Accuracy: 0.5923999547958374\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss: 0.7982673645019531 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss: 0.7722772359848022 Validation Accuracy: 0.5767999291419983\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss: 0.7982673645019531 Validation Accuracy: 0.5719999074935913\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss: 0.8019801378250122 Validation Accuracy: 0.589199960231781\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss: 0.8118811845779419 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss: 0.7970297336578369 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss: 0.7685643434524536 Validation Accuracy: 0.5747998952865601\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss: 0.8044553995132446 Validation Accuracy: 0.5811999440193176\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss: 0.8143565058708191 Validation Accuracy: 0.5931999683380127\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss: 0.8056930303573608 Validation Accuracy: 0.5877999067306519\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss: 0.7933168411254883 Validation Accuracy: 0.5763999223709106\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss: 0.7710396647453308 Validation Accuracy: 0.5745999217033386\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss: 0.801980197429657 Validation Accuracy: 0.5807998776435852\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss: 0.8180692195892334 Validation Accuracy: 0.593799889087677\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss: 0.7982673048973083 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss: 0.8094059228897095 Validation Accuracy: 0.5917999744415283\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss: 0.7896039485931396 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss: 0.7945544719696045 Validation Accuracy: 0.58079993724823\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss: 0.7957920432090759 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss: 0.7599009871482849 Validation Accuracy: 0.5841999053955078\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss: 0.7995049357414246 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss: 0.7896039485931396 Validation Accuracy: 0.5835999250411987\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss: 0.8007426261901855 Validation Accuracy: 0.579599916934967\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss: 0.7970297336578369 Validation Accuracy: 0.5821998715400696\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss: 0.780940592288971 Validation Accuracy: 0.5881999731063843\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss: 0.816831648349762 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss: 0.7957921028137207 Validation Accuracy: 0.5795998573303223\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss: 0.7945544123649597 Validation Accuracy: 0.5755999088287354\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss: 0.8056930303573608 Validation Accuracy: 0.5947999358177185\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss: 0.8106435537338257 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss: 0.8205445408821106 Validation Accuracy: 0.5829998850822449\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss: 0.7920792102813721 Validation Accuracy: 0.5819998979568481\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss: 0.7945543527603149 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss: 0.8155940175056458 Validation Accuracy: 0.5929999351501465\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss: 0.7995049357414246 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss: 0.8143564462661743 Validation Accuracy: 0.5809999108314514\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss: 0.8143564462661743 Validation Accuracy: 0.587399959564209\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss: 0.8007426261901855 Validation Accuracy: 0.5801999568939209\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss: 0.8168317079544067 Validation Accuracy: 0.5859999656677246\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss: 0.7933167815208435 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss: 0.8056930303573608 Validation Accuracy: 0.5809998512268066\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss: 0.8131187558174133 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss: 0.8019801378250122 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss: 0.8056930899620056 Validation Accuracy: 0.5877999067306519\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss: 0.7846534848213196 Validation Accuracy: 0.5881998538970947\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss: 0.8131188154220581 Validation Accuracy: 0.5797998905181885\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss: 0.8032178282737732 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss: 0.7957920432090759 Validation Accuracy: 0.5757999420166016\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss: 0.7908415794372559 Validation Accuracy: 0.5771999359130859\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss: 0.7896039485931396 Validation Accuracy: 0.5851999521255493\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss: 0.8106435537338257 Validation Accuracy: 0.5793998837471008\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss: 0.8019802570343018 Validation Accuracy: 0.5865998864173889\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss: 0.7834157943725586 Validation Accuracy: 0.579599916934967\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss: 0.7970296740531921 Validation Accuracy: 0.5775999426841736\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss: 0.8081682920455933 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss: 0.8056930303573608 Validation Accuracy: 0.585399866104126\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss: 0.8044553995132446 Validation Accuracy: 0.5847999453544617\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss: 0.8032177686691284 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss: 0.8007425665855408 Validation Accuracy: 0.5885999798774719\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss: 0.818069338798523 Validation Accuracy: 0.5897999405860901\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss: 0.8143563866615295 Validation Accuracy: 0.5849999785423279\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss: 0.8019801378250122 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss: 0.7945544719696045 Validation Accuracy: 0.5825998783111572\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss: 0.8143565058708191 Validation Accuracy: 0.5895999670028687\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss: 0.8007426261901855 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss: 0.8193069696426392 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss: 0.8044553995132446 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss: 0.7982673645019531 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss: 0.8143563866615295 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss: 0.7982673048973083 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss: 0.8143563866615295 Validation Accuracy: 0.5819998979568481\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss: 0.8056930899620056 Validation Accuracy: 0.5763998627662659\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss: 0.7920792102813721 Validation Accuracy: 0.573199987411499\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss: 0.8168317079544067 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss: 0.8007425665855408 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss: 0.8180692791938782 Validation Accuracy: 0.5837999582290649\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss: 0.7995049357414246 Validation Accuracy: 0.5817998647689819\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss: 0.7982673048973083 Validation Accuracy: 0.5709999203681946\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss: 0.7871286869049072 Validation Accuracy: 0.5781999230384827\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss: 0.7784653902053833 Validation Accuracy: 0.5847999453544617\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss: 0.7957921028137207 Validation Accuracy: 0.5781999230384827\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss: 0.7957921028137207 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss: 0.7908415794372559 Validation Accuracy: 0.5705999135971069\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss: 0.7549504637718201 Validation Accuracy: 0.5737999081611633\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss: 0.8032178282737732 Validation Accuracy: 0.593799889087677\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss: 0.7673267722129822 Validation Accuracy: 0.569599986076355\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss: 0.7747524976730347 Validation Accuracy: 0.5773999691009521\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss: 0.7524752616882324 Validation Accuracy: 0.5665999054908752\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss: 0.7896039485931396 Validation Accuracy: 0.5849998593330383\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss: 0.808168351650238 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss: 0.7871286869049072 Validation Accuracy: 0.5707999467849731\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss: 0.7896039485931396 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss: 0.7462871074676514 Validation Accuracy: 0.5605999231338501\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss: 0.8007425665855408 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss: 0.7920792102813721 Validation Accuracy: 0.590199887752533\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss: 0.7933168411254883 Validation Accuracy: 0.579599916934967\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss: 0.7883663773536682 Validation Accuracy: 0.5833999514579773\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss: 0.7784653306007385 Validation Accuracy: 0.5653999447822571\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss: 0.7846534848213196 Validation Accuracy: 0.582599937915802\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss: 0.801980197429657 Validation Accuracy: 0.5947998762130737\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss: 0.8118812441825867 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss: 0.8007426261901855 Validation Accuracy: 0.5835999250411987\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss: 0.7821781635284424 Validation Accuracy: 0.5741998553276062\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss: 0.7846534848213196 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss: 0.7995049953460693 Validation Accuracy: 0.5923998951911926\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss: 0.7970296740531921 Validation Accuracy: 0.5733999013900757\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss: 0.7945544719696045 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss: 0.8118811845779419 Validation Accuracy: 0.5819999575614929\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss: 0.7883663773536682 Validation Accuracy: 0.5831999778747559\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss: 0.8118811845779419 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss: 0.806930661201477 Validation Accuracy: 0.5805999040603638\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss: 0.7933168411254883 Validation Accuracy: 0.5809999108314514\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss: 0.8106435537338257 Validation Accuracy: 0.5817999839782715\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss: 0.7858911156654358 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss: 0.8118811845779419 Validation Accuracy: 0.5969998836517334\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss: 0.8131188154220581 Validation Accuracy: 0.5793998837471008\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss: 0.7883663773536682 Validation Accuracy: 0.5779999494552612\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss: 0.8118811249732971 Validation Accuracy: 0.5813999772071838\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss: 0.7623761892318726 Validation Accuracy: 0.5785999894142151\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss: 0.8081682920455933 Validation Accuracy: 0.5927999019622803\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss: 0.7797030210494995 Validation Accuracy: 0.5717999339103699\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss: 0.7896040081977844 Validation Accuracy: 0.5799999833106995\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss: 0.803217887878418 Validation Accuracy: 0.58899986743927\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss: 0.780940592288971 Validation Accuracy: 0.5767999291419983\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss: 0.7982673048973083 Validation Accuracy: 0.600399911403656\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss: 0.7883663773536682 Validation Accuracy: 0.5683999061584473\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss: 0.7982672452926636 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss: 0.8069307804107666 Validation Accuracy: 0.5875998735427856\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss: 0.7957921624183655 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss: 0.816831648349762 Validation Accuracy: 0.5973999500274658\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss: 0.7797029614448547 Validation Accuracy: 0.5767999887466431\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss: 0.806930661201477 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss: 0.7995049953460693 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss: 0.8044554591178894 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss: 0.8205445408821106 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss: 0.7858911156654358 Validation Accuracy: 0.5679999589920044\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss: 0.8069307208061218 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss: 0.7957921028137207 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss: 0.8118811845779419 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss: 0.8143563866615295 Validation Accuracy: 0.5951998829841614\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss: 0.7920791506767273 Validation Accuracy: 0.574199914932251\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss: 0.8118811249732971 Validation Accuracy: 0.5931999683380127\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss: 0.7945544123649597 Validation Accuracy: 0.5753999352455139\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss: 0.8217821717262268 Validation Accuracy: 0.586199939250946\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss: 0.8242573738098145 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss: 0.8044555187225342 Validation Accuracy: 0.5765998959541321\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss: 0.8056930303573608 Validation Accuracy: 0.5943998694419861\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss: 0.8032178282737732 Validation Accuracy: 0.5825998783111572\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss: 0.8155940771102905 Validation Accuracy: 0.5903998613357544\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss: 0.801980197429657 Validation Accuracy: 0.593799889087677\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss: 0.7970297336578369 Validation Accuracy: 0.5713999271392822\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss: 0.8044554591178894 Validation Accuracy: 0.5945999026298523\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss: 0.803217887878418 Validation Accuracy: 0.585599958896637\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss: 0.8205445408821106 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss: 0.8131188154220581 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss: 0.801980197429657 Validation Accuracy: 0.5765998959541321\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss: 0.8032178282737732 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss: 0.808168351650238 Validation Accuracy: 0.5849999189376831\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss: 0.8205445408821106 Validation Accuracy: 0.5863999724388123\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss: 0.8094059824943542 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss: 0.8056931495666504 Validation Accuracy: 0.5737999677658081\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss: 0.8056930899620056 Validation Accuracy: 0.5859999060630798\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss: 0.8106435537338257 Validation Accuracy: 0.591999888420105\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss: 0.8254950642585754 Validation Accuracy: 0.5939998626708984\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss: 0.8106435537338257 Validation Accuracy: 0.5905999541282654\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss: 0.7957921028137207 Validation Accuracy: 0.5745999217033386\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss: 0.8118811845779419 Validation Accuracy: 0.5881999731063843\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss: 0.8007425665855408 Validation Accuracy: 0.5847998857498169\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss: 0.8292078971862793 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss: 0.8155940771102905 Validation Accuracy: 0.5933998823165894\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss: 0.8007426261901855 Validation Accuracy: 0.579599916934967\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss: 0.8081682920455933 Validation Accuracy: 0.582599937915802\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss: 0.806930661201477 Validation Accuracy: 0.5819998979568481\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss: 0.8180692791938782 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss: 0.8019801378250122 Validation Accuracy: 0.586199939250946\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss: 0.7809405326843262 Validation Accuracy: 0.5737999081611633\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss: 0.7982673645019531 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss: 0.7896040081977844 Validation Accuracy: 0.5771999359130859\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss: 0.821782112121582 Validation Accuracy: 0.589199960231781\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss: 0.8094059228897095 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss: 0.8032178282737732 Validation Accuracy: 0.5823999643325806\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss: 0.7970297336578369 Validation Accuracy: 0.5847999453544617\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss: 0.8019802570343018 Validation Accuracy: 0.5761999487876892\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss: 0.8304455280303955 Validation Accuracy: 0.5905998349189758\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss: 0.7982673645019531 Validation Accuracy: 0.5895999073982239\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss: 0.7957921624183655 Validation Accuracy: 0.5801998972892761\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss: 0.7586633563041687 Validation Accuracy: 0.5731998682022095\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss: 0.8081682920455933 Validation Accuracy: 0.5781999230384827\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss: 0.8131187558174133 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss: 0.7809405326843262 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss: 0.7970297336578369 Validation Accuracy: 0.5841999053955078\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss: 0.766089141368866 Validation Accuracy: 0.5785999894142151\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss: 0.7920792102813721 Validation Accuracy: 0.5769999027252197\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss: 0.8044555187225342 Validation Accuracy: 0.5891999006271362\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss: 0.7920792698860168 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss: 0.801980197429657 Validation Accuracy: 0.5817998647689819\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss: 0.7982673048973083 Validation Accuracy: 0.5837999582290649\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss: 0.7871286869049072 Validation Accuracy: 0.5765998959541321\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss: 0.7908416390419006 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss: 0.8131188154220581 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss: 0.801980197429657 Validation Accuracy: 0.5833998918533325\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss: 0.7995049357414246 Validation Accuracy: 0.5851999521255493\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss: 0.7970297336578369 Validation Accuracy: 0.5715999603271484\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss: 0.7933168411254883 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss: 0.7982673645019531 Validation Accuracy: 0.5925999283790588\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss: 0.8094059228897095 Validation Accuracy: 0.5865998864173889\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss: 0.7945544123649597 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss: 0.7957920432090759 Validation Accuracy: 0.5689999461174011\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss: 0.7883663773536682 Validation Accuracy: 0.5887998938560486\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss: 0.8007426261901855 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss: 0.8131187558174133 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss: 0.8069307208061218 Validation Accuracy: 0.586199939250946\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss: 0.8106435537338257 Validation Accuracy: 0.5765998959541321\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss: 0.7920792102813721 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss: 0.8056930899620056 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss: 0.8217822313308716 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss: 0.8118811249732971 Validation Accuracy: 0.579599916934967\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss: 0.8032178282737732 Validation Accuracy: 0.5657998919487\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss: 0.7933168411254883 Validation Accuracy: 0.5833998918533325\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss: 0.7995049357414246 Validation Accuracy: 0.5867998600006104\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss: 0.8292079567909241 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss: 0.7834157347679138 Validation Accuracy: 0.5763999223709106\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss: 0.8044555187225342 Validation Accuracy: 0.568399965763092\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss: 0.7920792698860168 Validation Accuracy: 0.5805999636650085\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss: 0.7970297336578369 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss: 0.8230197429656982 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss: 0.77970290184021 Validation Accuracy: 0.5727999210357666\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss: 0.8131188154220581 Validation Accuracy: 0.5687999129295349\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss: 0.7772277593612671 Validation Accuracy: 0.5767998695373535\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss: 0.7945544719696045 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss: 0.8193069100379944 Validation Accuracy: 0.5941999554634094\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss: 0.7933167815208435 Validation Accuracy: 0.5759999752044678\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss: 0.8118811249732971 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss: 0.7784653902053833 Validation Accuracy: 0.5749999284744263\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss: 0.8094059824943542 Validation Accuracy: 0.5911999344825745\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss: 0.823019802570343 Validation Accuracy: 0.5965998768806458\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss: 0.8056930303573608 Validation Accuracy: 0.5769999027252197\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss: 0.8106435537338257 Validation Accuracy: 0.5757998824119568\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss: 0.7784653902053833 Validation Accuracy: 0.579599916934967\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss: 0.8056930899620056 Validation Accuracy: 0.5859999060630798\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss: 0.8081682920455933 Validation Accuracy: 0.5847999453544617\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss: 0.7995049357414246 Validation Accuracy: 0.579599916934967\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss: 0.8217821717262268 Validation Accuracy: 0.5775999426841736\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss: 0.7920792102813721 Validation Accuracy: 0.58079993724823\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss: 0.801980197429657 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss: 0.8230197429656982 Validation Accuracy: 0.5889999270439148\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss: 0.8267326951026917 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss: 0.8094059228897095 Validation Accuracy: 0.5787999033927917\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss: 0.7896040081977844 Validation Accuracy: 0.5775999426841736\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss: 0.8217822313308716 Validation Accuracy: 0.5921999216079712\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss: 0.8254950642585754 Validation Accuracy: 0.5969999432563782\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss: 0.8106436133384705 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss: 0.8279703259468079 Validation Accuracy: 0.5803998708724976\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss: 0.7871286869049072 Validation Accuracy: 0.5815999507904053\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss: 0.8267325758934021 Validation Accuracy: 0.5869999527931213\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss: 0.8403465151786804 Validation Accuracy: 0.5983998775482178\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss: 0.823019802570343 Validation Accuracy: 0.5859999656677246\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss: 0.8143564462661743 Validation Accuracy: 0.5743999481201172\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss: 0.8118811845779419 Validation Accuracy: 0.5811999440193176\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss: 0.8143564462661743 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss: 0.8242573738098145 Validation Accuracy: 0.5955999493598938\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss: 0.8341583609580994 Validation Accuracy: 0.5865998864173889\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss: 0.8403465151786804 Validation Accuracy: 0.5811998844146729\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss: 0.8069307208061218 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss: 0.8267326951026917 Validation Accuracy: 0.5915998816490173\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss: 0.823019802570343 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss: 0.8168317079544067 Validation Accuracy: 0.587399959564209\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss: 0.8292078971862793 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss: 0.7982673048973083 Validation Accuracy: 0.5785999298095703\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss: 0.8217821717262268 Validation Accuracy: 0.5859999656677246\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss: 0.8217821717262268 Validation Accuracy: 0.5953999161720276\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss: 0.8205445408821106 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss: 0.8254950046539307 Validation Accuracy: 0.5809999108314514\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss: 0.8094059228897095 Validation Accuracy: 0.5851999521255493\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss: 0.8304455280303955 Validation Accuracy: 0.5841999650001526\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss: 0.8292078971862793 Validation Accuracy: 0.5943999290466309\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss: 0.8329207301139832 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss: 0.8143564462661743 Validation Accuracy: 0.5753998756408691\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss: 0.821782112121582 Validation Accuracy: 0.5791998505592346\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss: 0.8193069100379944 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss: 0.8316831588745117 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss: 0.8452969789505005 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss: 0.7883663177490234 Validation Accuracy: 0.5689998865127563\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss: 0.8131188154220581 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss: 0.8267326951026917 Validation Accuracy: 0.5915998816490173\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss: 0.8353959918022156 Validation Accuracy: 0.5939999222755432\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss: 0.8378713130950928 Validation Accuracy: 0.5797999501228333\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss: 0.8131188154220581 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss: 0.8180692791938782 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss: 0.8304455280303955 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss: 0.8428217172622681 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss: 0.8415841460227966 Validation Accuracy: 0.587399959564209\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss: 0.7957921028137207 Validation Accuracy: 0.5651999115943909\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss: 0.8143565058708191 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss: 0.8279702663421631 Validation Accuracy: 0.5865998864173889\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss: 0.8378713130950928 Validation Accuracy: 0.5895999670028687\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss: 0.837871253490448 Validation Accuracy: 0.5815999507904053\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss: 0.8217822313308716 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss: 0.7920791506767273 Validation Accuracy: 0.5781998634338379\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss: 0.816831648349762 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss: 0.8353960514068604 Validation Accuracy: 0.5951999425888062\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss: 0.8329207897186279 Validation Accuracy: 0.5845999717712402\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss: 0.8304455280303955 Validation Accuracy: 0.5757999420166016\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss: 0.8056930303573608 Validation Accuracy: 0.5727999210357666\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss: 0.8106435537338257 Validation Accuracy: 0.5795999765396118\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss: 0.8292078971862793 Validation Accuracy: 0.5847998857498169\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss: 0.8279702663421631 Validation Accuracy: 0.5773999094963074\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss: 0.8242574334144592 Validation Accuracy: 0.574199914932251\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss: 0.8106435537338257 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss: 0.8155940771102905 Validation Accuracy: 0.5773999094963074\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss: 0.8341583609580994 Validation Accuracy: 0.5905999541282654\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss: 0.837871253490448 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss: 0.8143564462661743 Validation Accuracy: 0.5721999406814575\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss: 0.8069307208061218 Validation Accuracy: 0.5747999548912048\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss: 0.8032178282737732 Validation Accuracy: 0.5797999501228333\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss: 0.8329207897186279 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss: 0.8292078375816345 Validation Accuracy: 0.5809999704360962\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss: 0.821782112121582 Validation Accuracy: 0.5727999210357666\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss: 0.801980197429657 Validation Accuracy: 0.5781998634338379\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss: 0.7933167815208435 Validation Accuracy: 0.575999915599823\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss: 0.8143564462661743 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss: 0.8056931495666504 Validation Accuracy: 0.5847998857498169\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss: 0.816831648349762 Validation Accuracy: 0.5852000117301941\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss: 0.8415841460227966 Validation Accuracy: 0.5957999229431152\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss: 0.8032178282737732 Validation Accuracy: 0.5801998972892761\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss: 0.8007426261901855 Validation Accuracy: 0.5811998844146729\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss: 0.8155940771102905 Validation Accuracy: 0.5773999094963074\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss: 0.8131188154220581 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss: 0.8366336226463318 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss: 0.7920792102813721 Validation Accuracy: 0.5779998898506165\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss: 0.7982673048973083 Validation Accuracy: 0.5783998966217041\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss: 0.8254950642585754 Validation Accuracy: 0.5783999562263489\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss: 0.8155940771102905 Validation Accuracy: 0.584399938583374\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss: 0.806930661201477 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss: 0.7797030210494995 Validation Accuracy: 0.5717999339103699\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss: 0.7908416390419006 Validation Accuracy: 0.5755999088287354\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss: 0.8205446004867554 Validation Accuracy: 0.5751999020576477\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss: 0.8056930303573608 Validation Accuracy: 0.5793999433517456\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss: 0.8056930303573608 Validation Accuracy: 0.577799916267395\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss: 0.7846534252166748 Validation Accuracy: 0.5771998763084412\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss: 0.8118811845779419 Validation Accuracy: 0.5859999060630798\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss: 0.8106435537338257 Validation Accuracy: 0.5785999298095703\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss: 0.8131188154220581 Validation Accuracy: 0.5773999691009521\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss: 0.8081682920455933 Validation Accuracy: 0.5851999521255493\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss: 0.8007425665855408 Validation Accuracy: 0.5785999298095703\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss: 0.8118811845779419 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss: 0.7957921028137207 Validation Accuracy: 0.5729999542236328\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss: 0.8131188154220581 Validation Accuracy: 0.5761998891830444\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss: 0.8056930303573608 Validation Accuracy: 0.5847999453544617\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss: 0.7920792102813721 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss: 0.8143564462661743 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss: 0.816831648349762 Validation Accuracy: 0.5745999217033386\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss: 0.8143564462661743 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss: 0.8019802570343018 Validation Accuracy: 0.5795998573303223\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss: 0.8032177686691284 Validation Accuracy: 0.5843998789787292\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss: 0.8106436133384705 Validation Accuracy: 0.5781999826431274\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss: 0.8081682920455933 Validation Accuracy: 0.5739999413490295\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss: 0.8094059824943542 Validation Accuracy: 0.5849998593330383\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss: 0.7871286869049072 Validation Accuracy: 0.5739998817443848\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss: 0.8056930303573608 Validation Accuracy: 0.58079993724823\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss: 0.7957921028137207 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss: 0.7957921028137207 Validation Accuracy: 0.5761998891830444\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss: 0.8106436133384705 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss: 0.7982673048973083 Validation Accuracy: 0.583599865436554\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss: 0.806930661201477 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss: 0.8279702663421631 Validation Accuracy: 0.5785998702049255\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss: 0.7970296740531921 Validation Accuracy: 0.582599937915802\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss: 0.8118811845779419 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss: 0.8094059228897095 Validation Accuracy: 0.5865999460220337\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss: 0.7883663177490234 Validation Accuracy: 0.5719999074935913\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss: 0.8106435537338257 Validation Accuracy: 0.5763999223709106\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss: 0.7982673645019531 Validation Accuracy: 0.5767999291419983\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss: 0.8094059228897095 Validation Accuracy: 0.584399938583374\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss: 0.8180692791938782 Validation Accuracy: 0.582599937915802\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss: 0.8193069100379944 Validation Accuracy: 0.5857999324798584\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss: 0.8044554591178894 Validation Accuracy: 0.5705999135971069\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss: 0.8019802570343018 Validation Accuracy: 0.5773999094963074\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss: 0.7982673645019531 Validation Accuracy: 0.5859998464584351\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss: 0.8131187558174133 Validation Accuracy: 0.586199939250946\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss: 0.8180692791938782 Validation Accuracy: 0.5837999582290649\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss: 0.7957920432090759 Validation Accuracy: 0.5681999325752258\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss: 0.8007425665855408 Validation Accuracy: 0.5785999298095703\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss: 0.8044554591178894 Validation Accuracy: 0.5811999440193176\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss: 0.8019802570343018 Validation Accuracy: 0.5803998708724976\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss: 0.7995049357414246 Validation Accuracy: 0.5769999027252197\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss: 0.8279702663421631 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss: 0.8118811249732971 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss: 0.816831648349762 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss: 0.7995048761367798 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss: 0.8168317079544067 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss: 0.8403465747833252 Validation Accuracy: 0.5811998844146729\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss: 0.8193069100379944 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss: 0.8044554591178894 Validation Accuracy: 0.5791999101638794\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss: 0.8143564462661743 Validation Accuracy: 0.582599937915802\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss: 0.8131188154220581 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss: 0.8279702663421631 Validation Accuracy: 0.5815999507904053\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss: 0.8155940175056458 Validation Accuracy: 0.5877999067306519\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss: 0.823019802570343 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss: 0.8168317079544067 Validation Accuracy: 0.5829998850822449\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss: 0.816831648349762 Validation Accuracy: 0.5859999656677246\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss: 0.8403465747833252 Validation Accuracy: 0.5805999040603638\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss: 0.8143563866615295 Validation Accuracy: 0.5859999656677246\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss: 0.818069338798523 Validation Accuracy: 0.5841999053955078\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss: 0.8316831588745117 Validation Accuracy: 0.5851999521255493\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss: 0.8279702663421631 Validation Accuracy: 0.5845999121665955\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss: 0.8329207897186279 Validation Accuracy: 0.5785999298095703\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss: 0.8094059228897095 Validation Accuracy: 0.5855998992919922\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss: 0.8168317079544067 Validation Accuracy: 0.5817999839782715\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss: 0.8428217768669128 Validation Accuracy: 0.5849999189376831\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss: 0.823019802570343 Validation Accuracy: 0.5833999514579773\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss: 0.8428218364715576 Validation Accuracy: 0.586199939250946\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss: 0.8193069696426392 Validation Accuracy: 0.5845999717712402\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss: 0.8292078375816345 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss: 0.8180692195892334 Validation Accuracy: 0.5915999412536621\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss: 0.8155940771102905 Validation Accuracy: 0.58899986743927\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss: 0.8403465747833252 Validation Accuracy: 0.5847998857498169\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss: 0.8217821717262268 Validation Accuracy: 0.5815999507904053\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss: 0.8279702663421631 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss: 0.8440593481063843 Validation Accuracy: 0.5899999141693115\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss: 0.8217821717262268 Validation Accuracy: 0.589199960231781\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss: 0.8292078971862793 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss: 0.8217821717262268 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss: 0.8316830992698669 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss: 0.837871253490448 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss: 0.8193069100379944 Validation Accuracy: 0.5895999670028687\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss: 0.8230198621749878 Validation Accuracy: 0.5829998850822449\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss: 0.8279703259468079 Validation Accuracy: 0.5795999765396118\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss: 0.837871253490448 Validation Accuracy: 0.5835999250411987\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss: 0.8452970385551453 Validation Accuracy: 0.5907999277114868\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss: 0.821782112121582 Validation Accuracy: 0.5941998958587646\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss: 0.8428217172622681 Validation Accuracy: 0.5811998844146729\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss: 0.8316832184791565 Validation Accuracy: 0.5815999507904053\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss: 0.844059407711029 Validation Accuracy: 0.584399938583374\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss: 0.839108943939209 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss: 0.8292078971862793 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss: 0.8304455280303955 Validation Accuracy: 0.5819999575614929\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss: 0.8279702663421631 Validation Accuracy: 0.5801998972892761\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss: 0.8452970385551453 Validation Accuracy: 0.5831999778747559\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss: 0.8378713130950928 Validation Accuracy: 0.5931999087333679\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss: 0.8279702663421631 Validation Accuracy: 0.5889999270439148\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss: 0.8366336822509766 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss: 0.8403465151786804 Validation Accuracy: 0.5831998586654663\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss: 0.844059407711029 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss: 0.8403465747833252 Validation Accuracy: 0.5893999338150024\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss: 0.8254950046539307 Validation Accuracy: 0.590199887752533\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss: 0.839108943939209 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss: 0.8279702067375183 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss: 0.8490099310874939 Validation Accuracy: 0.5827999114990234\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss: 0.8477722406387329 Validation Accuracy: 0.5903999209403992\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss: 0.8292079567909241 Validation Accuracy: 0.5823999643325806\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss: 0.8366336822509766 Validation Accuracy: 0.5837998986244202\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss: 0.8316831588745117 Validation Accuracy: 0.5823999047279358\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss: 0.8502474427223206 Validation Accuracy: 0.5827999711036682\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss: 0.8403464555740356 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss: 0.8403465151786804 Validation Accuracy: 0.590799868106842\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss: 0.8477723002433777 Validation Accuracy: 0.5885999798774719\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss: 0.836633563041687 Validation Accuracy: 0.5835999846458435\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss: 0.8465346097946167 Validation Accuracy: 0.5781999230384827\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss: 0.8415842056274414 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss: 0.8341584801673889 Validation Accuracy: 0.5869998931884766\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss: 0.8440593481063843 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss: 0.8502474427223206 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss: 0.8514851331710815 Validation Accuracy: 0.5811998844146729\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss: 0.8452970385551453 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss: 0.8341584205627441 Validation Accuracy: 0.5881999731063843\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss: 0.8329207897186279 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss: 0.853960394859314 Validation Accuracy: 0.5819999575614929\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss: 0.837871253490448 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss: 0.8428217768669128 Validation Accuracy: 0.5901999473571777\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss: 0.8378711938858032 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss: 0.8353959918022156 Validation Accuracy: 0.5829998850822449\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss: 0.8465346097946167 Validation Accuracy: 0.5847998857498169\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss: 0.8353959918022156 Validation Accuracy: 0.5817999839782715\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss: 0.8316832184791565 Validation Accuracy: 0.5919999480247498\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss: 0.8341584205627441 Validation Accuracy: 0.590999960899353\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss: 0.8465346097946167 Validation Accuracy: 0.5845999121665955\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss: 0.8539604544639587 Validation Accuracy: 0.5889999866485596\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss: 0.8428217768669128 Validation Accuracy: 0.5801998972892761\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss: 0.8304455876350403 Validation Accuracy: 0.5855998992919922\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss: 0.8304455280303955 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss: 0.8329207897186279 Validation Accuracy: 0.5815999507904053\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss: 0.8428217768669128 Validation Accuracy: 0.5883998870849609\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss: 0.8465346693992615 Validation Accuracy: 0.5813999176025391\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss: 0.8378713130950928 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss: 0.8341583609580994 Validation Accuracy: 0.5929998755455017\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss: 0.8514851331710815 Validation Accuracy: 0.5855998992919922\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss: 0.8502475023269653 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss: 0.8502475619316101 Validation Accuracy: 0.5755999088287354\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss: 0.8292078971862793 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss: 0.8353960514068604 Validation Accuracy: 0.5879999399185181\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss: 0.8490098714828491 Validation Accuracy: 0.5883999466896057\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss: 0.8514850735664368 Validation Accuracy: 0.587399959564209\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss: 0.8452969789505005 Validation Accuracy: 0.5787999033927917\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss: 0.844059407711029 Validation Accuracy: 0.5885999202728271\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss: 0.8329207897186279 Validation Accuracy: 0.5897998809814453\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss: 0.8465346097946167 Validation Accuracy: 0.5849998593330383\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss: 0.855198085308075 Validation Accuracy: 0.5867999196052551\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss: 0.8304455280303955 Validation Accuracy: 0.5789998769760132\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss: 0.8279702663421631 Validation Accuracy: 0.587399959564209\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss: 0.839108943939209 Validation Accuracy: 0.5913999080657959\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss: 0.8428217768669128 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss: 0.8564355969429016 Validation Accuracy: 0.5863999128341675\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss: 0.8366336226463318 Validation Accuracy: 0.5717999339103699\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss: 0.8155940771102905 Validation Accuracy: 0.5829999446868896\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss: 0.8254950642585754 Validation Accuracy: 0.5875999331474304\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss: 0.8428218364715576 Validation Accuracy: 0.5889999270439148\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss: 0.853960394859314 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss: 0.8403465151786804 Validation Accuracy: 0.5735999345779419\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss: 0.818069338798523 Validation Accuracy: 0.5867999792098999\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss: 0.8391088247299194 Validation Accuracy: 0.5901998281478882\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss: 0.8490099906921387 Validation Accuracy: 0.5905998945236206\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss: 0.8465346097946167 Validation Accuracy: 0.5853999853134155\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss: 0.8403465151786804 Validation Accuracy: 0.5713999271392822\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss: 0.801980197429657 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss: 0.818069338798523 Validation Accuracy: 0.583599865436554\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss: 0.8353960514068604 Validation Accuracy: 0.5861998796463013\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss: 0.837871253490448 Validation Accuracy: 0.5881999135017395\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss: 0.8341584205627441 Validation Accuracy: 0.5733999013900757\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss: 0.818069338798523 Validation Accuracy: 0.5793999433517456\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss: 0.8316831588745117 Validation Accuracy: 0.579599916934967\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss: 0.8180692791938782 Validation Accuracy: 0.585399866104126\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss: 0.8452969789505005 Validation Accuracy: 0.5873998999595642\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss: 0.8267326354980469 Validation Accuracy: 0.5707999467849731\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss: 0.8205445408821106 Validation Accuracy: 0.5821999311447144\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss: 0.8267326354980469 Validation Accuracy: 0.586199939250946\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss: 0.8267326951026917 Validation Accuracy: 0.5845999121665955\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss: 0.8316831588745117 Validation Accuracy: 0.5805999040603638\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss: 0.8353960514068604 Validation Accuracy: 0.5689998865127563\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss: 0.8378713130950928 Validation Accuracy: 0.5853999257087708\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss: 0.8267326354980469 Validation Accuracy: 0.5837999582290649\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss: 0.8230197429656982 Validation Accuracy: 0.5803998708724976\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss: 0.8428217172622681 Validation Accuracy: 0.5853999257087708\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss: 0.8440594673156738 Validation Accuracy: 0.579599916934967\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss: 0.8341583609580994 Validation Accuracy: 0.5851998925209045\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss: 0.8242574334144592 Validation Accuracy: 0.5823999643325806\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss: 0.8304455280303955 Validation Accuracy: 0.5781999826431274\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss: 0.8353960514068604 Validation Accuracy: 0.582599937915802\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss: 0.8329207301139832 Validation Accuracy: 0.577799916267395\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss: 0.8452969789505005 Validation Accuracy: 0.5865998864173889\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss: 0.8279703259468079 Validation Accuracy: 0.5839998722076416\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss: 0.8267326951026917 Validation Accuracy: 0.578999936580658\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss: 0.8341584205627441 Validation Accuracy: 0.5805999636650085\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss: 0.8403465151786804 Validation Accuracy: 0.5757999420166016\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss: 0.836633563041687 Validation Accuracy: 0.5831999182701111\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss: 0.8316832184791565 Validation Accuracy: 0.5837999582290649\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss: 0.8143564462661743 Validation Accuracy: 0.5755999088287354\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss: 0.8391088843345642 Validation Accuracy: 0.5825998783111572\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss: 0.8415840864181519 Validation Accuracy: 0.5799999237060547\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss: 0.8230197429656982 Validation Accuracy: 0.5809999704360962\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss: 0.8267326354980469 Validation Accuracy: 0.5817999243736267\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss: 0.8353960514068604 Validation Accuracy: 0.5737999081611633\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss: 0.8440593481063843 Validation Accuracy: 0.5905999541282654\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss: 0.8490098714828491 Validation Accuracy: 0.577799916267395\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss: 0.8254950642585754 Validation Accuracy: 0.5803999304771423\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss: 0.8329207897186279 Validation Accuracy: 0.5809999704360962\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss: 0.8576732873916626 Validation Accuracy: 0.5767999291419983\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss: 0.8403464555740356 Validation Accuracy: 0.5871999263763428\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss: 0.8465346097946167 Validation Accuracy: 0.5803999900817871\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss: 0.8329207897186279 Validation Accuracy: 0.5821998715400696\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss: 0.8205446004867554 Validation Accuracy: 0.5683998465538025\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss: 0.8242573738098145 Validation Accuracy: 0.5781998634338379\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss: 0.8329208493232727 Validation Accuracy: 0.58079993724823\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss: 0.8403465151786804 Validation Accuracy: 0.579599916934967\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss: 0.8490098714828491 Validation Accuracy: 0.5859999060630798\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss: 0.8106435537338257 Validation Accuracy: 0.5757999420166016\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss: 0.8341584205627441 Validation Accuracy: 0.5765998959541321\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss: 0.8353959918022156 Validation Accuracy: 0.585399866104126\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss: 0.8267326951026917 Validation Accuracy: 0.5758000016212463\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss: 0.8353960514068604 Validation Accuracy: 0.5909999012947083\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss: 0.8378713130950928 Validation Accuracy: 0.5787999629974365\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss: 0.8428217172622681 Validation Accuracy: 0.5839999318122864\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss: 0.8304455280303955 Validation Accuracy: 0.5847999453544617\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss: 0.8403465151786804 Validation Accuracy: 0.5761998891830444\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss: 0.8292078971862793 Validation Accuracy: 0.5837998390197754\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.5958605706691742\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d2dbad978>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
